{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train,y_train),(X_test,y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Playing with shape\n",
    "#x_temp=X_train\n",
    "#x_temp.reshape(-1,60000).shape\n",
    "x_temp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(X_train[i],cmap=\"gray\")\n",
    "    plt.title(str(y_train[i]))\n",
    "    plt.axis(\"off\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,20))\n",
    "for i in range(6):\n",
    "    ax = fig.add_subplot(1,6,i+1,xticks=[],yticks=[])\n",
    "    ax.imshow(X_train[i],cmap=\"gray\")\n",
    "    ax.set_title(str(y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rescale [0,255] -> [0,1]\n",
    "X_train = X_train.astype(\"float32\")/255\n",
    "X_test = X_test.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OnehotLabel\n",
    "import pandas as pd\n",
    "y_train=np.array(pd.get_dummies(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Reshaping X_train\n",
    "X_train_matrix = X_train.reshape(60000,-1)\n",
    "X_train_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Activation\n",
    "model = Sequential()\n",
    "model.add(Dense(32,input_dim=X_train_matrix.shape[1]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_matrix,y_train,epochs=200,batch_size=124,verbose=1)\n",
    "score = model.evaluate(X_train_matrix,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_flatten = X_test.reshape(X_test.shape[0],-1)\n",
    "y_test_one_hot = np.array(pd.get_dummies(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_test = model.evaluate(X_test_flatten,y_test_one_hot)\n",
    "score_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model in Lecture\n",
    "from keras.layers import Dropout\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(512,input_dim=X_train_matrix.shape[1]))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(512))\n",
    "model1.add(Dropout(0.7))\n",
    "model1.add(Dense(10,activation=\"softmax\"))\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss=\"categorical_crossentropy\",optimizer=\"rmsprop\",metrics=[\"accuracy\"])\n",
    "score_1 = model1.evaluate(X_test_flatten,y_test_one_hot)\n",
    "100*score_1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(filepath=\"./best_weight_mnist.hdf5\",verbose=1,\n",
    "                              save_best_only=True)\n",
    "hist = model1.fit(X_train_matrix,y_train,batch_size=128,epochs=6,validation_split=0.2,\n",
    "                 callbacks=[checkpointer],verbose=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_1 = model1.evaluate(X_test_flatten,y_test_one_hot)\n",
    "100*score_1[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##OK WITH Lossing DATA then PADDING = \"VALID\"\n",
    "# IF NOT OK WITH LOSSING THE DATA THEN PADDING = \"SAME\"\n",
    "#Depends on the stride of our filter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D\n",
    "Conv2D(filters,kernel_size,strides,padding,activation=\"relu\",input_shape)\n",
    "#filters - the number of filter\n",
    "#Kernel_size - number specifying both height and width of (square)\n",
    "#convolution window.\n",
    "#activation-typically relu.if not specify anything then no activation function\n",
    "#strongly encouraged to specify relu in activation \n",
    "#strides-the stride of convolution , if not specified then default is 1.\n",
    "#padding - one of \"valid\" or \"same\" if nothing is not specified then by default is set to \"valid\"\n",
    "#NOTE : it is possible to reperesent both kernel_size and strides as either a number or a tuple\n",
    "#When using your convolution layer as the first layer (appearing after the input layer)in a model,we must provide a input shape\n",
    "#And donot specify a input shape if its not the first layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Say I'm constructing a CNN and my input layer accepts a grayscale images that are \n",
    "#200by200 pixels(corresponding to a 3D array with height 200, width 200 depth 1).Then\n",
    "#say I'd like the next layer to be a convolution layer with 16 filters,each with width and \n",
    "#height of 3. When performing the convoultion, I'd like the filter to jump two pixels\n",
    "#at a time. I also don't want the filter to extend outside of the image bondaries \n",
    "#in other words,I don't want to pad the images with zeros. Then, to construct this convolution \n",
    "#layer, I would use the following line of command\n",
    "\n",
    "\n",
    "\n",
    "Conv2D(filters=16,kernel_size=2,strides=2,activation=\"relu\",input_shape=(200,200,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Say I'd like the next layer in my CNN to be a convolution layer that takes \n",
    "#the layer constructed in Example 1 as input. Say I'd like my new layer to have 32 \n",
    "#filters,each with a height and width of 3.When performing convolution, I'd like the filter \n",
    "#to jump 1 pixels at a time. I want the convolution layer to see all regions of previous layer, and \n",
    "#so I don't mind if the filter hangs over the edge of previous layer when its performing\n",
    "#the convolution. Then, to construct this convolution layer I would use following\n",
    "#line of code\n",
    "Conv2D(filters=32,kernel_size=3,padding=\"same\",activation=\"relu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this case, there are 64 filters and the size of filter is (2x2), and the \n",
    "#layer has a Relu activation function.The other arguments in the layer use the\n",
    "#default values, so this convolution uses a stride of 1 and the padding is set to\n",
    "#\"valid\"(so no padding)\n",
    "Conv2D(64,(2,2),activation=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16,kernel_size=2,strides=2,padding=\"valid\",activation=\"relu\",\n",
    "                input_shape = (200,200,1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Take note how the number of parameter in the convolution layer changes\n",
    "## Params # 80 \n",
    "## also notice the shape of the convolution layer changes . This corresponds\n",
    "# to value under Output shape in the printed output.\n",
    "# None corresponds to the batch size, and the convolution layer has. a height of 100,\n",
    "# width of 100 and depth of 16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formula: Number of Parameter in a convolution Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of parameter in a covolution layer depends on the supplied values of **filters**, **kernel_size** and **input_shape**.\n",
    "K - the number of filter in a convolution layer\n",
    "F -  the height and width of convolution filters\n",
    "D_in - the depth of previous layer\n",
    "Notice that K = filters and F=kernel_size . likewise D_in the last value in the input_shape tuple.\n",
    "Since there are (**F x F x D_in**) weights per filter, and the convolution layer is composed of K filters, the total number of weights in convolution layer is equal to **K x F x F x D_in** and there is a bias term per filter thus the number of parameters in convolution layer is give by **(K x F x F x D_in + K)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2*2*16*1 + 16\n",
    "## Above example number of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formula: Shape of a Convolution Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of a convoution layer depends on the supplied values of **kernel_size, input_shape, padding** and **stride**.\n",
    "* K - the number of filter in the convolution layer \n",
    "* F - the height and width of convolution filters\n",
    "* S - the stride of convolution filters\n",
    "* H_in - the height of the previous layer\n",
    "* W_in - the width of the previous layer\n",
    "Notice that K = filters , F = kernel_size and S = stride and H_in and W_in is equal to first and second value of input_shape respectively.\n",
    "* The depth of convolution layer will be always be equal to **K**(no of filter)\n",
    "IF **padding = \"same\"**, then spatial dimension of the convolution layer are the following\n",
    "* height = ceil(float(H_in)/float(S))\n",
    "* width = ceil(float(W_in)/float(S))\n",
    "If **padding = \"valid\"**, then spatial dimension of the convolution layer are the following:\n",
    "* height = ceil(float(H_in - F +1)/float(S))\n",
    "* width = ceil(float(W_in - F +1)/float(S))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32,kernel_size=3,strides=2,padding=\"same\",\n",
    "                activation = \"relu\",input_shape=(128,128,3)))\n",
    "model.summary()\n",
    "#Depth of convolution layer is equal to number of filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polling of layers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max Pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So if want to find a complex pattern in our data then we will have many filters \n",
    "#and dimentionalty we will increase thus it will overfit our training data\n",
    "#THAT is the reason we introduce polling layer.\n",
    "#first we will discuss about max polling layer \n",
    "#Max Pooling Layer\n",
    "#Window Size: 2*2\n",
    "#Strides 2\n",
    "# So it reduces the dimension of convolution layer (Half of original size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global average Pooling Layer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A global average pooling layer takes a 3D array and turns it into a vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Pooling Layers in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import MaxPooling2D\n",
    "MaxPooling2D(pool_size=2,strides=2,padding=\"valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments\n",
    "* pool_size - Number specifying the height and width of the pooling window\n",
    "* strides - The vertical and horizontal stride. IF don't specify anything,strides will default to pool_size\n",
    "* padding - One of the \"valid\" or \"same\". If don't specify anything padding is set to \"valid\"\n",
    "Input could be number or tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example \n",
    "Say I'm constructing a CNN, and I'd like to reduce the dimentionality of a convolution layer by following it with a max pooling layer.Say the convolution layer has size **(100,100,15)** and I'd like the max pooling layer to have a size **(50,50,15)**. I can do this by using 2 x 2 window in my max pooling layer, with a stride of 2,which could be constructed in the following line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaxPooling2D(pool_size=2,strides=2)\n",
    "# IF you'd like to use a stride of 1, but still keep the size of window at \n",
    "#2 x 2 then we could use\n",
    "MaxPooling2D(pool_size=2,strides=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the Dimentionality of Max Pooling Layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "model = Sequential()\n",
    "model.add(MaxPooling2D(pool_size=2,strides=2,input_shape=(100,100,15)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16,kernel_size=2,padding=\"same\",activation=\"relu\",\n",
    "                input_shape=(32,32,3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation=\"relu\",))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dense(10,activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to Remember\n",
    "* Always add a ReLU activation to Conv2D layer in your CNN. With the exception of the final layer in the network, Dense layers should also have a ReLU activation function\n",
    "* When constructing a network for classification, the final layer in the network should be a dense layer with a Softmax activation function. The number of nodes in the final layer should be equal the total number of classes in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 --CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "from keras.datasets import cifar10\n",
    "\n",
    "# LOAD THE PRE -SHUFFLED TRAIN AND TEST DATA\n",
    "(x_train,y_train),(x_test,y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "fig = plt.figure(figsize=(20,5))\n",
    "for i in range(36):\n",
    "    ax = fig.add_subplot(3,12,i+1,xticks=[],yticks=[])\n",
    "    ax.imshow(np.squeeze(x_train[i])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the data\n",
    "x_train = x_train.astype(\"float32\")/255\n",
    "x_test=x_test.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "import pandas as pd\n",
    "#one hot encoding in keras\n",
    "num_classes = len(np.unique(y_train))\n",
    "y_train = keras.utils.to_categorical(y_train,num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#break data into training and validation set\n",
    "(x_train,x_valid)=x_train[5000:],x_train[:5000]\n",
    "(y_train,y_valid)=y_train[5000:],y_train[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_train.shape)\n",
    "#print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Infereing\n",
    "print(x_train.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print number of training, validation ,and test images\n",
    "print(x_train.shape[0],\"training samples\")\n",
    "print(x_test.shape[0],\"testing samples\")\n",
    "print(x_valid.shape[0],\"validating samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Model-- Regular Vanilla Neural Network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#falttening of image \n",
    "x_train_vanilla = x_train.reshape(x_train.shape[0],-1)\n",
    "x_valid_vanilla = x_valid.reshape(x_valid.shape[0],-1)\n",
    "x_test_vanilla = x_test.reshape(x_test.shape[0],-1)\n",
    "print(x_train_vanilla.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vanilla Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "model = Sequential()\n",
    "model.add(Dense(1000,activation=\"relu\",input_dim=x_train_vanilla.shape[1]))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512,activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes,activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"rmsprop\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model!!\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "#train model\n",
    "checkpointer = ModelCheckpoint(filepath=\"MLP.weights.best.hdf5\",verbose=1,\n",
    "                              save_best_only=True)\n",
    "hist = model.fit(x_train_vanilla,y_train,batch_size=32,epochs=20,\n",
    "                validation_data=(x_valid_vanilla,y_valid),callbacks=[checkpointer],\n",
    "                verbose=2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the weights that yeilds the best calidation accuracy\n",
    "model.load_weights(\"MLP.weights.best.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Checking the accuracy\n",
    "accuracy=model.evaluate(x_test_vanilla,y_test)\n",
    "print(100*accuracy[1],\"Testing accuracy of the data in vanilla model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Model --CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16,activation=\"relu\",padding=\"same\",kernel_size=2,\n",
    "                input_shape=(x_train.shape[1],x_train.shape[2],x_train.shape[3])))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=32,activation=\"relu\",padding=\"same\",kernel_size=2))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64,activation=\"relu\",padding=\"same\",kernel_size=2))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024,activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(510,activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes,activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compling the model\n",
    "from keras import optimizers\n",
    "adam = optimizers.Adam()\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=adam,\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpointer_cnn = ModelCheckpoint(filepath=\"CNN.best.weights.hdf5\",\n",
    "                                  verbose=1,save_best_only=True)\n",
    "model.fit(x_train,y_train,verbose=2,batch_size=124,epochs=10,\n",
    "          callbacks=[checkpointer_cnn],validation_data=(x_valid,y_valid),\n",
    "         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"CNN.best.weights.hdf5\")\n",
    "score = model.evaluate(x_test,y_test)\n",
    "print(100*score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(100*score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Agumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "checkpoint = ModelCheckpoint(filepath=\"CNN.aug_best.weights.hdf5\",save_best_only=True,verbose=2)\n",
    "datagen = ImageDataGenerator(featurewise_center=True,featurewise_std_normalization=True,\n",
    "                            rotation_range=20,width_shift_range=0.2,height_shift_range=0.2,\n",
    "                            horizontal_flip=True)\n",
    "datagen.fit(x_train)\n",
    "hist = model.fit_generator(datagen.flow(x_train,y_train,batch_size=124),steps_per_epoch=len(x_train)/124,epochs=100,\n",
    "                          callbacks=[checkpoint],validation_data = (x_valid,y_valid),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"CNN.aug_best.weights.hdf5\")\n",
    "score = model.evaluate(x_test,y_test)\n",
    "print(100*score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(100*score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Config Agumented Image Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen_train = ImageDataGenerator(width_shift_range=0.1,\n",
    "                                  height_shift_range=0.1,\n",
    "                                  horizontal_flip = True)\n",
    "datagen_train.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#take a subset of training data\n",
    "x_train_subset = x_train[:12]\n",
    "\n",
    "#Visualize subset of taining data\n",
    "fig = plt.figure(figsize=(20,2))\n",
    "for i in range(0,len(x_train_subset)):\n",
    "    ax = fig.add_subplot(1,12,i+1,xticks=[],yticks=[])\n",
    "    ax.imshow(x_train_subset[i])\n",
    "fig.suptitle(\"Subset of Original Training Images\",fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "# Visualize agumented images\n",
    "fig = plt.figure(figsize=(20,2))\n",
    "for x_batch in datagen_train.flow(x_train_subset,batch_size=12):\n",
    "    for i in range(0,12):\n",
    "        ax = fig.add_subplot(1,12,i+1,xticks=[],yticks=[])\n",
    "        ax.imshow(x_batch[i])\n",
    "    fig.suptitle(\"Agumented Images\",fontsize=20)\n",
    "    plt.show()\n",
    "    break;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16,activation=\"relu\",padding=\"same\",kernel_size=2,\n",
    "                input_shape=(x_train.shape[1],x_train.shape[2],x_train.shape[3])))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=32,activation=\"relu\",padding=\"same\",kernel_size=2))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64,activation=\"relu\",padding=\"same\",kernel_size=2))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_classes,activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "batch_size=32\n",
    "epochs =100\n",
    "checkpointer=ModelCheckpoint(filepath=\"CNN.aug_best.weights.hdf5\",\n",
    "                            verbose=1,save_best_only=True)\n",
    "model.fit_generator(datagen_train.flow(x_train,y_train,batch_size=batch_size),\n",
    "                                      epochs=epochs,verbose=2,callbacks=[checkpointer],\n",
    "                                      validation_data=(x_valid,y_valid),\n",
    "                                      validation_steps=x_valid.shape[0]//batch_size,\n",
    "                                      steps_per_epoch=x_train.shape[0]//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
