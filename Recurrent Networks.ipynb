{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network -- RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RNN is used in many application such as \n",
    "* Speech recognition\n",
    "* Machine tansition \n",
    "* Video analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network architectures you've seen so far were trained using the current output. In other words, our system did not have any __memory__ elements. RNNs address this very basic and important issue by using __memory__(i.e. past inputs to the network) when producing the current output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent :  Occuring often or repeatdly.\n",
    "* We perform same task for each element in the input sequence.\n",
    " ***\n",
    "* FEEDFORWARD NEURAL NETWORK\n",
    "    * NONLINEAR FUNCTION APPROXIMATION\n",
    "    * TRAINING \n",
    "        * Backpropagation\n",
    "        * Stochastic Gradient Descent\n",
    "    * EVALUATION\n",
    "    \n",
    "    \n",
    "    \n",
    "***\n",
    "\n",
    "\n",
    "### Recurrent neural network -- RNN\n",
    "* APPLICATION \n",
    "* SIMPLE RNN ELMAN NETWORK \n",
    "* TRAINING RNNs\n",
    "* LSTM - LONG SHORT TERM MEMORY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bit of history\n",
    "How did the theory behind RNN evolve? Where were we a few years ago and where are we now?\n",
    "* After the first wave of artifical neural network in the mid 80s,it became clear that feedforward networks are limited since they are unable to capture temporal dependencies, which as we said before are dependencies that change over time.\n",
    "* By the way biological neural networks have recurring connections, so applying recurrence to artifical feedforward neural networks made natural sense.\n",
    "* First approach to add memory to neural networks were time delay neural network (TDNN) (1989)\n",
    "\n",
    "* In TDNNs input from past timesteps were introduced to the network input, changing the actual external inputs.\n",
    "    * This had the advantage of clearly allowing the network to look beyond the current timestep,but also introduce to clear disadvantage, since the temporal dependencies were limited to the window of the time chosen.\n",
    "    \n",
    "    \n",
    "### Simple RNN/ ELMAN NETWORK \n",
    "* Simple RNNs also know as Elman networks and Jordan networks, were next to follow.\n",
    "\n",
    "* It was recognized in the early 90s that all of these networks suffer from what we call, vanishing gardient problem:\n",
    "    * In which contribution of information deacyed geometrically over time\n",
    "    * So capturing relationships that spanned more than eight or ten steps back was practically impossible.\n",
    "    \n",
    "## LSTM \n",
    "* They were invented to address the problem of __vansihing gradient__\n",
    "* The key novelty in LSTMs was the idea that some signals, what we call state variables, can be kept fixed by using gates, and reintroduced or not at an appropriate time in future.\n",
    "* In this way, arbitrary time intervals can be represented, and temporal dependencies can be captured.\n",
    "* Variation on LSTMs such as Gated Recurrent Networks, or GRU in short.\n",
    "* __GRU__ we will not be focusing on GRU in this lession.\n",
    "* [LINK TO GRU](https://deeplearning4j.org/lstm.html) documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPLICATIONS\n",
    "* Leading tech companies are all using RNNs, particulary LSTMs, in their applications\n",
    "* Speech Recognition, where a sequence of data samples extracted from an audio signal continuously mapped to text. -- Apple Siri\n",
    "* All of them use RNNa as a part of their speech recognition software.\n",
    "* Time series predictions, where we predict traffic patterns on specific roads to help drivers optimize their driving paths, like they do in waze.\n",
    "* Or predicting what movies a consumer will want to watch next, like they do in Netflix.\n",
    "* Prediction stock price movements based on the historical patterns of stock movement and potentially other market conditions, that change over time -- practice by most quantitative hedge funds. \n",
    "* NLP  such as machine translation.\n",
    "    * machine translation \n",
    "    * question answering \n",
    "    * chatbots\n",
    "* Gesture Recognition\n",
    "* where we observe a sequence of video frame to determine which gesture the user has made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN AND RNN\n",
    "* One can use CNN for first few layers for features extractions and at the end can use RNN for analysing sequnece of data and use memory feature of RNN -- popular example is Gesture analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revision of vanilla FFNN\n",
    "* Two main type of applications\n",
    "    * Classification (1/0)\n",
    "    * Regression (time series forcasting)\n",
    "* Our task is to find the best possible weights.\n",
    "* In FFNN we have static mapping from the inputs to the outputs.\n",
    "* We use the word static as we have no memory and output only depends on the inputs and the weights.\n",
    "* SO FOR SAME WEIGHTS AND SAME INPUTS WE WILL ALWAYS RECEIVE SAME OUTPUT.\n",
    "\n",
    "* Two primary phases \n",
    "    * Training \n",
    "    * Evaluation\n",
    "* GOAL -- To yield a network that genralizes beyond the train set.\n",
    "\n",
    "\n",
    "* Trainig phase \n",
    "    * FeedForward\n",
    "    * Backpropagation\n",
    "* which we will repeat until we decide that our system is as it can be.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* With RNN we perform same task for each element in the input sequence\n",
    "* RNN's also attempt to address the need for capturing information by maintaing internal memory elements, also known as **STATES**.\n",
    "* Two fundamental diffrences between RNNs and FNNs are:\n",
    "    * Manner by which we define our inputs and outputs, Instead of using single-input and single-output at each time step, we train with **sequences** since previous inputs matter.\n",
    "    * The second difference, stems from the memory elements that RNNs host.\n",
    "    * Current inputs,as well as **activation of neurons** serve as inputs to the **next time step**.\n",
    "* In FNN there is input without any feedback.\n",
    "* **MEMORY**:which is equal to the output of the hidden layer.\n",
    "* **\n",
    "* **\n",
    "* In FNN the output at any time is the function of the current input and weights only.\n",
    "    * We assume that input are independent of each other therefore there is no significance sequence.\n",
    "    * So we actually train the system by randomly drawing inputs and target pairs.\n",
    "* In RNNs the output at time t, depends not only on the current inputs and weights, but also on previous inputs such as input at time t-1,t-2,t-3...\n",
    "* Hidden layer is represented by s(states).\n",
    "* Wx:repersents the weight matrix connecting the input to the state layer.\n",
    "* Wy:repersents the weight matrix connecting the state tot the ouput \n",
    "* Ws: represents the weight matrix, connecting the state from the **previous timestep** to the state in the **next timestep**.\n",
    "* Signal s is feedback to the system.\n",
    "* Since the input is spread over time and we perform the same task for every element in the sequence, we unfold the model in time and represent it the following way.\n",
    "\n",
    "* **RNNs share same parameters during each timestep**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN -- unfolded model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation through time(BPTT)\n",
    "* When using RNN we use backpropagation through time.\n",
    "* We don't train network specific to time t.\n",
    "* We train a network in a specific time t as well as take into account all that has happened before.\n",
    "* So when we have to calculate gradients of __t3__ states we also have to consider about __t1 and t2__ states.\n",
    "* Capturing relationships that span more than __8 to 10 steps__ back is practically impossible due to __vanishing gradient__ problem.\n",
    "### Training in RNN\n",
    "* Training in mini batches using Gradient Descent\n",
    "    * Updating weights in every N steps reduces the __complexity__!.\n",
    "    * And reduces the noise \n",
    "    \n",
    "    \n",
    "### Exploding Gradient Problem\n",
    "* The gradient grows uncontrollably\n",
    "    * Solution -- Gradient Clipping.\n",
    "    * So in timestep T \n",
    "    * If gradient **exceeds the threshold** then we normalize the gradient.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM -- Long Short-Term Memory Cell\n",
    "* The goal of LSTM is to overcome the vanishing Gradient Problem\n",
    "* Certain Inputs can be stored(latched) for long peroid of time without being forgotten.\n",
    "* In LSTM we want to avoid the loss of the information or the vanishing gradient problem.\n",
    "    * By intentionally latching(storing) on some information over many timesteps\n",
    " * The main idea with LSTM cells are:\n",
    "     * They can decide which information to remove or forget.\n",
    "     * Which information to store and when to use it.\n",
    "     * The cell can also decide when to move the previous states information to next.\n",
    "     * With help of SIGMOID function we decide about dataflow.\n",
    "     * All data passes through when sigmoid output is 1.\n",
    "     * And negligible data passes through when sigmoid output is 0.\n",
    "     * These three sigmoid acts as a mechanism to filter:\n",
    "         * what goes into the cell\n",
    "         * What retains within the cell\n",
    "         * What passes to the output\n",
    "         * These three gating functions(weights) are also trained using backpropagation by adjusting the weights that feed into them "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "* RNN have a hard time storing long term memory and this is where LSTMs or long term memory networks will come to rescue.\n",
    "* The fundamental difference between RNN and LSTM is in RNN it has only short term memory and in LSTM it has both Long-Term memory and as well as Short-Term Memory too.\n",
    "* And In LSTM in every step long and short term memory is merged and from it a new long term and short term memory is generated and a output.\n",
    "* In LSTM we give more importance to old memory.\n",
    "* **\n",
    "* **\n",
    "### LSTM example\n",
    "* __Long Term Memory__\n",
    "    * Show about nature and Science\n",
    "    * Lots of forest animals\n",
    "* __Short Term Memory__\n",
    "    * Squirrels\n",
    "    * Tree\n",
    "* __Event__\n",
    "    * Dog/Wolf\n",
    "* **\n",
    "\n",
    "* We will be using Long Term and Short Term Memory and the current event to update our __Long Term Memory__\n",
    "* And then we will update our __Short Term Memory__ with the help of previous long short term memory and current event.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of RNN and LSTM\n",
    "\n",
    "### Character-wise RNN\n",
    "* That is,the network will learn about some text one character at a time and then generate new text one character at a time.\n",
    "* Let's say we want to generate new Shakespeare plays.\n",
    "    * For example \"To be not to be\"\n",
    "* We'd pass the sequence into out RNN one character at a time.\n",
    "* Once trained the network will generate new text by predicting the next character based on the character it's already seen.\n",
    "* So to train this network we wanted to predict the next character in the input sequence.\n",
    "* In this way the network will learn to produce a sequence of character that look like the original text.\n",
    "* First let's unrool the RNN so we can see how this all works as a sequence.\n",
    "### Training of the model\n",
    "* Here we will pass our input vector(character) as the **one-hot encoded**.\n",
    "* These vector goes to the hidden layer \n",
    "* The hidden layer is build up of LSTM cells, where the hidden state and cell pass from one cell to the next in sequence.\n",
    "* IN practice in LSTM we use multiple layer LSTM CELL hidden layer.\n",
    "* **THE OUTPUT LAYER PREDICT THE NEXT CHARACTER**\n",
    "* We want probabilites for each character the same way we did in the image classification.\n",
    "* SO we want softmax activation function in our output layer.\n",
    "* **So our target will be the input sequence shifted by one.**SO each character is predicting the next character in the sequence.\n",
    "* Again we will be using cross-entropy loss function for training with gradient descent.\n",
    "* When this network is trained up we can pass in one character and get out probabiliy distribution for the likely next character.\n",
    "* Then we can use sample from the distribution to get next character and so on.(loop it!)\n",
    "### SEQUENCE BATCHING\n",
    "* In RNN one of the most difficult part of building networks for me is getting the batches right.\n",
    "    * ITs more of programming challenge than anyting deep learning specific.\n",
    "* With RNNS we're training on sequence of data like text, stock values, audio etc.\n",
    "* By taking a sequence and splitting it into multiple shorter sequences, we can take advantage of matrix operations to make training more efficient.\n",
    "* ** Infact the RNN is training on multiple sequence in parallel**\n",
    "* For example\n",
    "    * If we have sequence from 1 to 12\n",
    "    * We can pass these into an RNN as one sequence.\n",
    "    * What better. We could split it in half and pass in two sequences.\n",
    "    * The batch size corresponds to the number of sequence we're using.\n",
    "    * Along batch size we also choose the length of sequences we feed into the network.\n",
    "    * We can retain the hidden state from one batch and use it at the start of the next batch.\n",
    "    * This way sequence information is transferred across batches for each mini sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Output\n",
    "* Here we'll create the output layer.\n",
    "* We need to connect the output of the RNN cells to a fully connected layer with a softmax output. The softmax output give us a probability distribution we can use to predict the next character, so we want this layer to have size C, the number of classes/character we have in our text.\n",
    "* IF our input has batch size **N**, number of steps **M**, and the hidden layer has **L** hidden units, then the output is a 3D tensor with size **N x M x L.** The output of each LSTM cell has size L, we have M of them , one of each sequence  step amd we have N sequences. So the total size is $N \\times M \\times L$ \n",
    "* We are using the same fully conneceted layer. the same weight, for each of the outputs. Then, to make things easier we should reshape the outputs into a 2D tensor with shape $(M*N) \\times L$. That is, one row for each sequence and step, where the values of each row are the output form LSTM cells. We get the LSTM output as a list, `lstm_ouptut`. \n",
    "* First we need to concatenate this whole list into one array with `tf.concat`. Then reshape it with (tf.reshape) to size $(M * N) \\times L$\n",
    "* Once we have output reshaped, we can think of matrix multiplication with weights. we need to wrap the weight and bias variables in a variable scope with `tf.variable_scope(scope_name)`.\n",
    "* Because there are weights being created here in the LSTM cells. Tensorflow will throw an error if the weights created here have the same names as the weights created in the LSTM cells, which they will be default, To avoid this, we wrap the variables in a variable scope so we can give them a unique names.  \n",
    "* So one thing we need to do is to put our weights and biases in a varaible scope.\n",
    "* So what is happening is that the RNN layers, that RNN cells, are defining wieights within themselves, But the problem is that you're going to get an error because you can't have multiple weights named the same thing and they're named the same thing by default.\n",
    "* So if we didn't have a variable scope here then we could try to create this variable for the weights it would have the same name as the weights created in the RNN cells.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Build a Network \n",
    "So far we just sort of build all the pieces and now we have to put it tog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* So since LSTMs let the cells state flow through sort of unimpeded then you don't have to really worry about the gradients disappearing.\n",
    "* However gradient can still explode get really big.\n",
    "    * So we clip the gradients.\n",
    "    * So we just set some threshold if gradient is greater than that threshold, we just set it to the threshold.\n",
    "* So in this way you can make sure that your gradient never grow too big.\n",
    "* So in this code here is just using tf.clip_by_global_norm,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "* Now we can put all the pieces together and build a class of network. To actually run data through the LSTM cells, we will use **tf.nn.dynamic_rnn**.\n",
    "* This function will pass the hidden and cell state across LSTM cell appropriately for us.\n",
    "* It returns the outputs for each step for each sequence in the mini-batch. \n",
    "* It also give us the final LSTM **state**.\n",
    "* We want to save this final state as final_state so **we can pass it to the first LSTM cell in the next mini-batch run**.\n",
    "* For tf.nn.dynamic_rnn, we pass in the cell and intial state we get from build_lstm, as well as our input sequence. Also, we need to one-hot encoded the inputs before going into the RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Hyperparameters\n",
    "Here are the hyperparameter for the networks,\n",
    "* `batch_size` - Number of sequences running through the network in one pass.\n",
    "* `num_Steps`(sequence length)-Number of characters in a the sequence the networ is trained on. Larger is better typically, the network will learn more long range dependencies. But will take longer to train.100 is a good number here.\n",
    "* `lstm_size`-The number of units in the hidden layers.\n",
    "* `num_layers`-Number of hidden LSTM layers to use\n",
    "* `learning_rate`-Learning rate for training\n",
    "* `keeo_prob`-The dropout keep probability when training. If you're network is overfitting, try decrease this.\n",
    "\n",
    "Here's some good advice from Andrej Karpathy the network. I'm going to copy it in here for your benefit, but also link to where it orginally came from.\n",
    "\n",
    "># Tips and Tricks\n",
    "\n",
    ">## Monitoring Validation Loss vs. Training Loss\n",
    "\n",
    "> If you're somewhat new to Machine Learning or Neural Networks it can take a bit of expertise to get good models. The most important quantity to keep track of is the difference between your training loss (printed during training) and the validation loss(printed once in a while when the RNN is run on the validation data(by default every 1000 iterations)\n",
    ">* If your training loss is much lower than validation loss then this means the network might be **overfitting**. Solutions to this are to decrease your network size, or to increase dropout.\n",
    ">* If your training/validation loss are about equal then your model is **underfitting**. Increase the size of your model (either number of layers or the raw number of neurons per layer)\n",
    "\n",
    "\n",
    ">## Approximate number of parameters\n",
    "\n",
    ">Th two most important parametes that control the model are `lstm_size` and `num_layers`.**I would advise that you always use num_layers of either 2/3**. The `lstm_size` can be adjusted based on how much data you have. The two important quantities to keep track of here are:\n",
    ">* The number of parameters in your model. This printed when you start training.\n",
    ">* The size of your dataset. 1MB file is approximately 1 million characters.\n",
    ">**These two should be about the same order of magnitude. It's a little tricky to tell**.Here are some examples:\n",
    ">* I have a 100MB dataset and I'm using the default parameter settings (which currently print 150k parameters). **My data size is significantly larger (100 million > 0.15 million)**, so I expect it to **heavily underfit**. I am thinking I can comfortably afford to make larger lstm_size.\n",
    ">* I have a 100MB dataset and running a 10 million  parameter model. I'm slightly nervous and I'm carefully monitoring my valdiation loss then I may want to try to increase dropout bit and see if that helps validation loss.\n",
    "\n",
    "\n",
    ">## Best Models Strategy\n",
    "> The winning strategy to obtaning very good models (if you have the computer and time) is to aleays err on making the network larger (as large as you're willing to wait for it to compute) and then try different dropout values (between 0,1). Whenever model has the best validation performance (the loss, written in the checkpoint filename, low is good) is the one you should use in the end.\n",
    "\n",
    ">It is very common in deep learning to run many different models with many different hyperparameter settings, and in the end take whatever checkpoint gave the best validation performance.\n",
    "\n",
    ">By the way, the size of your training and valdation splits are also parameters. Make sure you have decent amount of data in your valdation set or otherwise the validation performance will be noisy and not very informative. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN from scratch using TensorFlow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/unnatsingh/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('anna.txt','r') as f:\n",
    "    text = f.read()\n",
    "vocab = set(text)\n",
    "vocab_to_int = {i:c for c,i in enumerate(vocab)}\n",
    "int_to_vocab = dict(enumerate(vocab))\n",
    "encoded = np.array([vocab_to_int[word] for word in text],dtype = np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(int_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 81,\n",
       " ' ': 30,\n",
       " '!': 74,\n",
       " '\"': 38,\n",
       " '$': 67,\n",
       " '%': 13,\n",
       " '&': 28,\n",
       " \"'\": 80,\n",
       " '(': 51,\n",
       " ')': 9,\n",
       " '*': 32,\n",
       " ',': 19,\n",
       " '-': 63,\n",
       " '.': 73,\n",
       " '/': 64,\n",
       " '0': 49,\n",
       " '1': 33,\n",
       " '2': 79,\n",
       " '3': 62,\n",
       " '4': 18,\n",
       " '5': 47,\n",
       " '6': 70,\n",
       " '7': 56,\n",
       " '8': 14,\n",
       " '9': 12,\n",
       " ':': 45,\n",
       " ';': 43,\n",
       " '?': 78,\n",
       " '@': 57,\n",
       " 'A': 0,\n",
       " 'B': 16,\n",
       " 'C': 29,\n",
       " 'D': 21,\n",
       " 'E': 41,\n",
       " 'F': 44,\n",
       " 'G': 53,\n",
       " 'H': 23,\n",
       " 'I': 42,\n",
       " 'J': 34,\n",
       " 'K': 17,\n",
       " 'L': 3,\n",
       " 'M': 76,\n",
       " 'N': 4,\n",
       " 'O': 20,\n",
       " 'P': 31,\n",
       " 'Q': 15,\n",
       " 'R': 82,\n",
       " 'S': 48,\n",
       " 'T': 66,\n",
       " 'U': 10,\n",
       " 'V': 54,\n",
       " 'W': 61,\n",
       " 'X': 5,\n",
       " 'Y': 68,\n",
       " 'Z': 55,\n",
       " '_': 26,\n",
       " '`': 6,\n",
       " 'a': 22,\n",
       " 'b': 25,\n",
       " 'c': 37,\n",
       " 'd': 11,\n",
       " 'e': 52,\n",
       " 'f': 59,\n",
       " 'g': 77,\n",
       " 'h': 75,\n",
       " 'i': 71,\n",
       " 'j': 8,\n",
       " 'k': 72,\n",
       " 'l': 58,\n",
       " 'm': 46,\n",
       " 'n': 60,\n",
       " 'o': 24,\n",
       " 'p': 7,\n",
       " 'q': 50,\n",
       " 'r': 1,\n",
       " 's': 40,\n",
       " 't': 39,\n",
       " 'u': 36,\n",
       " 'v': 35,\n",
       " 'w': 65,\n",
       " 'x': 27,\n",
       " 'y': 2,\n",
       " 'z': 69}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29, 75, 22,  7, 39, 52,  1, 30, 33, 81, 81, 81, 23, 22,  7,  7,  2,\n",
       "       30, 59, 22, 46, 71, 58, 71, 52, 40, 30, 22,  1, 52, 30, 22, 58, 58,\n",
       "       30, 22, 58, 71, 72, 52, 43, 30, 52, 35, 52,  1,  2, 30, 36, 60, 75,\n",
       "       22,  7,  7,  2, 30, 59, 22, 46, 71, 58,  2, 30, 71, 40, 30, 36, 60,\n",
       "       75, 22,  7,  7,  2, 30, 71, 60, 30, 71, 39, 40, 30, 24, 65, 60, 81,\n",
       "       65, 22,  2, 73, 81, 81, 41, 35, 52,  1,  2, 39, 75, 71, 60], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chapter 1\\n\\n\\nHappy families are all alike; every unhappy family is unhappy in its own\\nway.\\n\\nEverythin'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(arr,batch_size,nsteps):\n",
    "    chara_per_batch =batch_size*nsteps\n",
    "    n_batches = len(arr)//chara_per_batch\n",
    "    factor = n_batches*chara_per_batch\n",
    "    \n",
    "    arr = arr[:factor]\n",
    "    arr = arr.reshape((batch_size,-1))\n",
    "    \n",
    "    for k in range(0,arr.shape[1],nsteps):\n",
    "        x_batch = arr[:,(k):((k)+nsteps)]\n",
    "        y_temp = arr[:,((k+1)):((k+1)+nsteps)]\n",
    "        \n",
    "        y_batch = np.zeros(x_batch.shape,dtype=x_batch.dtype)\n",
    "        y_batch[:,:y_temp.shape[1]] = y_temp\n",
    "        yield x_batch,y_batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batches = get_batches(encoded, 10, 50)\n",
    "x1, y1 = next(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      " [[29 75 22  7 39 52  1 30 33 81]\n",
      " [30 22 46 30 60 24 39 30 77 24]\n",
      " [35 71 60 73 81 81 38 68 52 40]\n",
      " [60 30 11 36  1 71 60 77 30 75]\n",
      " [30 71 39 30 71 40 19 30 40 71]\n",
      " [30 42 39 30 65 22 40 81 24 60]\n",
      " [75 52 60 30 37 24 46 52 30 59]\n",
      " [43 30 25 36 39 30 60 24 65 30]\n",
      " [39 30 71 40 60 80 39 73 30 66]\n",
      " [30 40 22 71 11 30 39 24 30 75]]\n",
      "\n",
      "y\n",
      " [[75 22  7 39 52  1 30 33 81 81]\n",
      " [22 46 30 60 24 39 30 77 24 71]\n",
      " [71 60 73 81 81 38 68 52 40 19]\n",
      " [30 11 36  1 71 60 77 30 75 71]\n",
      " [71 39 30 71 40 19 30 40 71  1]\n",
      " [42 39 30 65 22 40 81 24 60 58]\n",
      " [52 60 30 37 24 46 52 30 59 24]\n",
      " [30 25 36 39 30 60 24 65 30 40]\n",
      " [30 71 40 60 80 39 73 30 66 75]\n",
      " [40 22 71 11 30 39 24 30 75 52]]\n"
     ]
    }
   ],
   "source": [
    "print('x\\n', x1[:10, :10])\n",
    "print('\\ny\\n', y1[:10, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_inputs(batch_size, num_steps):\n",
    "    '''\n",
    "        Creating Placeholder\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    inputs = tf.placeholder(shape=[batch_size,num_steps],dtype=tf.int32,name=\"inputs\")\n",
    "    targets = tf.placeholder(shape=(batch_size,num_steps),dtype=tf.int32,name=\"targets\")\n",
    "    \n",
    "    keep_prob = tf.placeholder(dtype=tf.float32,name=\"keep_prob\")\n",
    "    \n",
    "    return inputs,targets,keep_prob\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an LSTM Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_lstm(lstm_size,num_layers,batch_size , keep_prob):\n",
    "    \n",
    "    \n",
    "    \n",
    "    def build_cell(lstm_size,keep_prob):\n",
    "        lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "        \n",
    "        drop = tf.contrib.rnn.DropoutWrapper(lstm,output_keep_prob=keep_prob)\n",
    "        return drop\n",
    "    \n",
    "    cell = tf.contrib.rnn.MultiRNNCell([(build_cell(lstm_size,keep_prob)) for _ in range(num_layers)])\n",
    "    intial_state = cell.zero_state(batch_size,tf.float32)\n",
    "    return cell,intial_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_output(lstm_output,in_size,out_size):\n",
    "    print(\"shape of lstm_out\"+str(lstm_output.get_shape()))\n",
    "    #seq_output = tf.concat(lstm_output,axis=1)\n",
    "    #print(\"shapeof seq_output\"+str(seq_output.get_shape()))\n",
    "    seq_output = lstm_output\n",
    "    x = tf.reshape(seq_output,[-1,in_size])\n",
    "    \n",
    "    \n",
    "    with tf.variable_scope('softmax'):\n",
    "        softmax_w = tf.Variable(tf.truncated_normal([in_size,out_size],stddev=0.1))\n",
    "        softmax_b = tf.Variable(tf.zeros(out_size))\n",
    "        \n",
    "        \n",
    "    logits = tf.add(tf.matmul(x,softmax_w),softmax_b)\n",
    "    print(\"shapeof seq_output\"+str(seq_output.get_shape()))\n",
    "    \n",
    "    out = tf.nn.softmax(logits,name=\"prediction\")\n",
    "    return out,logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_loss(logits,targets,lstm_size,num_classes):\n",
    "    y_one_hot = tf.one_hot(targets,num_classes)\n",
    "    y_reshaped = tf.reshape(y_one_hot,logits.get_shape())\n",
    "    \n",
    "    \n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=y_reshaped)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_optimizer(loss,learning_rate,grad_clip):\n",
    "    tvars = tf.trainable_variables()\n",
    "    grads,_ = tf.clip_by_global_norm(tf.gradients(loss,tvars),grad_clip)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate)\n",
    "    optimizer = train_op.apply_gradients(zip(grads,tvars))\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharRNN:\n",
    "    \n",
    "    \n",
    "    def __init__(self,num_classes,batch_size=64,num_steps=50,lstm_size=50,\n",
    "                num_layers=2,learning_rate=0.001,grad_clip=5,\n",
    "                 sampling=False):\n",
    "        \n",
    "        if sampling == True:\n",
    "            batch_size,num_steps=1,1\n",
    "        else :\n",
    "            batch_size,num_steps = batch_size,num_steps\n",
    "        \n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.inputs, self.targets,self.keep_prob = build_inputs(batch_size,num_steps)\n",
    "        \n",
    "        cell, self.initial_state = build_lstm(lstm_size,num_layers,batch_size,\n",
    "                                             self.keep_prob)\n",
    "        \n",
    "        x_one_hot = tf.one_hot(self.inputs,num_classes)\n",
    "        print(x_one_hot.get_shape())\n",
    "        outputs, state = tf.nn.dynamic_rnn(cell,x_one_hot,initial_state = self.initial_state)\n",
    "        self.final_state = state\n",
    "        print(\"shape of ouput\"+str(outputs.get_shape()))\n",
    "        \n",
    "        \n",
    "        self.prediction, self.logits = build_output(outputs,lstm_size,num_classes)\n",
    "        print(\"shape of logits\"+str(self.logits.get_shape()))\n",
    "        \n",
    "        self.loss = build_loss(self.logits,self.targets,lstm_size,num_classes)\n",
    "        self.optimizer = build_optimizer(self.loss, learning_rate, grad_clip)\n",
    "        \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 10  # number of batches\n",
    "num_steps = 50  # Number of sequence steps per batch\n",
    "lstm_size = 128  # Size of hidden layer in LSTMs\n",
    "num_layers = 2    # Number of LSTM layers \n",
    "learning_rate = 0.01   ## Learning Rate\n",
    "keep_prob = 0.5   # Dropout keep probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 50, 83)\n",
      "shape of ouput(10, 50, 128)\n",
      "shape of lstm_out(10, 50, 128)\n",
      "shapeof seq_output(10, 50, 128)\n",
      "shape of logits(500, 83)\n",
      "Epoch: 1/5...  Training Step: 50...  Training loss: 3.0976...  0.0803 sec/batch\n",
      "Epoch: 1/5...  Training Step: 100...  Training loss: 2.6868...  0.0973 sec/batch\n",
      "Epoch: 1/5...  Training Step: 150...  Training loss: 2.4605...  0.1083 sec/batch\n",
      "Epoch: 1/5...  Training Step: 200...  Training loss: 2.4211...  0.0724 sec/batch\n",
      "Epoch: 1/5...  Training Step: 250...  Training loss: 2.3386...  0.0740 sec/batch\n",
      "Epoch: 1/5...  Training Step: 300...  Training loss: 2.2072...  0.0733 sec/batch\n",
      "Epoch: 1/5...  Training Step: 350...  Training loss: 2.1169...  0.0866 sec/batch\n",
      "Epoch: 1/5...  Training Step: 400...  Training loss: 2.1631...  0.0780 sec/batch\n",
      "Epoch: 1/5...  Training Step: 450...  Training loss: 2.2193...  0.1067 sec/batch\n",
      "Epoch: 1/5...  Training Step: 500...  Training loss: 2.2705...  0.0785 sec/batch\n",
      "Epoch: 1/5...  Training Step: 550...  Training loss: 1.9663...  0.0988 sec/batch\n",
      "Epoch: 1/5...  Training Step: 600...  Training loss: 1.8836...  0.0799 sec/batch\n",
      "Epoch: 1/5...  Training Step: 650...  Training loss: 1.9074...  0.0969 sec/batch\n",
      "Epoch: 1/5...  Training Step: 700...  Training loss: 1.9005...  0.1410 sec/batch\n",
      "Epoch: 1/5...  Training Step: 750...  Training loss: 2.0433...  0.0714 sec/batch\n",
      "Epoch: 1/5...  Training Step: 800...  Training loss: 1.9464...  0.1037 sec/batch\n",
      "Epoch: 1/5...  Training Step: 850...  Training loss: 2.0715...  0.0883 sec/batch\n",
      "Epoch: 1/5...  Training Step: 900...  Training loss: 1.9665...  0.0778 sec/batch\n",
      "Epoch: 1/5...  Training Step: 950...  Training loss: 1.9972...  0.0997 sec/batch\n",
      "Epoch: 1/5...  Training Step: 1000...  Training loss: 1.8971...  0.0832 sec/batch\n",
      "Epoch: 1/5...  Training Step: 1050...  Training loss: 2.0086...  0.0841 sec/batch\n",
      "Epoch: 1/5...  Training Step: 1100...  Training loss: 1.8738...  0.0754 sec/batch\n",
      "Epoch: 1/5...  Training Step: 1150...  Training loss: 1.9443...  0.0841 sec/batch\n",
      "Epoch: 1/5...  Training Step: 1200...  Training loss: 1.9046...  0.0963 sec/batch\n",
      "Epoch: 1/5...  Training Step: 1250...  Training loss: 1.7068...  0.0730 sec/batch\n",
      "Epoch: 1/5...  Training Step: 1300...  Training loss: 1.8433...  0.0837 sec/batch\n",
      "Epoch: 1/5...  Training Step: 1350...  Training loss: 1.7671...  0.1234 sec/batch\n",
      "Epoch: 1/5...  Training Step: 1400...  Training loss: 1.9772...  0.0810 sec/batch\n",
      "Epoch: 1/5...  Training Step: 1450...  Training loss: 1.8259...  0.0731 sec/batch\n",
      "Epoch: 1/5...  Training Step: 1500...  Training loss: 1.8895...  0.0917 sec/batch\n",
      "Epoch: 1/5...  Training Step: 1550...  Training loss: 1.8238...  0.0736 sec/batch\n",
      "Epoch: 1/5...  Training Step: 1600...  Training loss: 1.9392...  0.0739 sec/batch\n",
      "Epoch: 1/5...  Training Step: 1650...  Training loss: 1.7812...  0.0729 sec/batch\n",
      "Epoch: 1/5...  Training Step: 1700...  Training loss: 1.8549...  0.0850 sec/batch\n",
      "Epoch: 1/5...  Training Step: 1750...  Training loss: 1.9077...  0.0881 sec/batch\n",
      "Epoch: 1/5...  Training Step: 1800...  Training loss: 1.8864...  0.0748 sec/batch\n",
      "Epoch: 1/5...  Training Step: 1850...  Training loss: 1.9186...  0.0733 sec/batch\n",
      "Epoch: 1/5...  Training Step: 1900...  Training loss: 1.6857...  0.0725 sec/batch\n",
      "Epoch: 1/5...  Training Step: 1950...  Training loss: 1.7858...  0.0738 sec/batch\n",
      "Epoch: 1/5...  Training Step: 2000...  Training loss: 1.8291...  0.0880 sec/batch\n",
      "Epoch: 1/5...  Training Step: 2050...  Training loss: 1.9647...  0.0918 sec/batch\n",
      "Epoch: 1/5...  Training Step: 2100...  Training loss: 1.7941...  0.0757 sec/batch\n",
      "Epoch: 1/5...  Training Step: 2150...  Training loss: 1.7631...  0.0990 sec/batch\n",
      "Epoch: 1/5...  Training Step: 2200...  Training loss: 1.7653...  0.0934 sec/batch\n",
      "Epoch: 1/5...  Training Step: 2250...  Training loss: 1.8046...  0.0764 sec/batch\n",
      "Epoch: 1/5...  Training Step: 2300...  Training loss: 1.6441...  0.0728 sec/batch\n",
      "Epoch: 1/5...  Training Step: 2350...  Training loss: 1.8822...  0.0780 sec/batch\n",
      "Epoch: 1/5...  Training Step: 2400...  Training loss: 1.8800...  0.0813 sec/batch\n",
      "Epoch: 1/5...  Training Step: 2450...  Training loss: 1.9455...  0.0769 sec/batch\n",
      "Epoch: 1/5...  Training Step: 2500...  Training loss: 1.7600...  0.0783 sec/batch\n",
      "Epoch: 1/5...  Training Step: 2550...  Training loss: 1.8063...  0.0741 sec/batch\n",
      "Epoch: 1/5...  Training Step: 2600...  Training loss: 1.7353...  0.0759 sec/batch\n",
      "Epoch: 1/5...  Training Step: 2650...  Training loss: 1.9856...  0.0783 sec/batch\n",
      "Epoch: 1/5...  Training Step: 2700...  Training loss: 1.8492...  0.0820 sec/batch\n",
      "Epoch: 1/5...  Training Step: 2750...  Training loss: 1.7214...  0.0813 sec/batch\n",
      "Epoch: 1/5...  Training Step: 2800...  Training loss: 1.6521...  0.0815 sec/batch\n",
      "Epoch: 1/5...  Training Step: 2850...  Training loss: 1.8707...  0.0860 sec/batch\n",
      "Epoch: 1/5...  Training Step: 2900...  Training loss: 1.6638...  0.0731 sec/batch\n",
      "Epoch: 1/5...  Training Step: 2950...  Training loss: 1.5771...  0.0742 sec/batch\n",
      "Epoch: 1/5...  Training Step: 3000...  Training loss: 1.7343...  0.1006 sec/batch\n",
      "Epoch: 1/5...  Training Step: 3050...  Training loss: 1.8481...  0.0725 sec/batch\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-9fbd5ff9b7fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m                                               \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                                               model.optimizer],\n\u001b[0;32m---> 32\u001b[0;31m                                              feed_dict=feed)\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprint_every_n\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "print_every_n = 50\n",
    "\n",
    "save_every_n = 200\n",
    "\n",
    "model = CharRNN(len(vocab),batch_size=batch_size,num_steps=num_steps,\n",
    "               lstm_size=lstm_size,num_layers=num_layers,\n",
    "                learning_rate=learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "saver=tf.train.Saver(max_to_keep=100)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    counter = 0 \n",
    "    for e in range(epochs):\n",
    "        \n",
    "        new_state = sess.run(model.initial_state)\n",
    "        loss =0 \n",
    "        for x,y in get_batches(encoded,batch_size,num_steps):\n",
    "            #print(x.shape)\n",
    "            counter += 1\n",
    "            start = time.time()\n",
    "            feed = {model.inputs:x,model.targets:y,\n",
    "                   model.keep_prob:keep_prob,\n",
    "                   model.initial_state:new_state}\n",
    "            batch_loss,new_state,_ = sess.run([model.loss,\n",
    "                                              model.final_state,\n",
    "                                              model.optimizer],\n",
    "                                             feed_dict=feed)\n",
    "            \n",
    "            if (counter % print_every_n == 0):\n",
    "                end = time.time()\n",
    "                print('Epoch: {}/{}... '.format(e+1, epochs),\n",
    "                      'Training Step: {}... '.format(counter),\n",
    "                      'Training loss: {:.4f}... '.format(batch_loss),\n",
    "                      '{:.4f} sec/batch'.format((end-start)))\n",
    "        \n",
    "            if (counter % save_every_n == 0):\n",
    "                saver.save(sess, \"checkpoints/i{}_l{}.ckpt\".format(counter, lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.train.get_checkpoint_state('checkpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling\n",
    "Now that the network is trained, we'll can use it to generate new text. The idea is that we pass in a character, then the network will predict the next character. We can use the new one , to predict the next one. And we keep doing this to generate new text. We also included some functionality to prime the network with some text by passing in a string and bulding ip a state from that.\n",
    "\n",
    "**The network gives us the predictions for each character. To reduce the noise and make things a little less random, we only choose a new character from top N most likely characters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pick_top_n(preds,vocab_size,top_n=5):\n",
    "    p = np.squeeze(preds) \n",
    "    # we squeeze the ouput here because the preds shape is (1,num_classes)\n",
    "    # so we change it into in [num_classes]\n",
    "    p[np.argsort(p)[:-top_n]] = 0\n",
    "    # in the above line we arrange the probability in ascending order and the \n",
    "    # least probability is equated to 0 and only top words with highest probability\n",
    "    # is kept to reduce noise.\n",
    "    p = p/np.sum(p)\n",
    "    # above we have normalized our p\n",
    "    c = np.random.choice(vocab_size,1,p=p)[0]\n",
    "    return c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,  23,   4,   5,   6,   2,   5,  64,  12, 532, 234,   3,  34,  23])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,23,4,5,6,2,5,64,12,532,234,3,34,23])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[np.argsort(a)[:-4]] = 0\n",
    "a1 = a/np.sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.07407407,  0.        ,  0.61574074,\n",
       "        0.27083333,  0.        ,  0.03935185,  0.        ])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(checkpoint, n_samples, lstm_size, vocab_size, prime = 'The '):\n",
    "    samples = [c for c in prime]\n",
    "    model = CharRNN(len(vocab),lstm_size=lstm_size,sampling=True)\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess,checkpoint)\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        for c in prime:\n",
    "            x = np.zeros((1,1))\n",
    "            x[0,0]=vocab_to_int[c]\n",
    "            feed = {model.inputs:x,\n",
    "                   model.keep_prob:1.\n",
    "                   model.initial_state:new_state}\n",
    "            preds,new_state = sess.run([model.prediction,model.final_state,\n",
    "                                       feed_dict=feed])\n",
    "        c = pick_top_n(preds,len(vocab))\n",
    "        sample.append(((int_to_vocab[c])))\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            x[0,0] = c\n",
    "            feed = {model.inputs:x,\n",
    "                   model.keep_prob:1.,\n",
    "                   model.initial_state:new_state}\n",
    "            preds,new_state = sess.run([modle.prediction,modle.final_state],\n",
    "                                      feed_dict:feed)\n",
    "            \n",
    "            c = pick_top_n(preds,len(vocab))\n",
    "            samples.append(int_to_vocab[c])\n",
    "            \n",
    "    return ''.join(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prime = 'The '\n",
    "a=[c for c in prime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 66.]]\n",
      "[[ 75.]]\n",
      "[[ 52.]]\n",
      "[[ 30.]]\n"
     ]
    }
   ],
   "source": [
    "for c in prime:\n",
    "    x = np.zeros((1,1))\n",
    "    x[0,0] = vocab_to_int[c]\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#checkpoint = 'checkpoints/i200_l512.ckpt'\n",
    "checkpoint = 'checkpoints/i66200_l128.ckpt'\n",
    "samp = sample(checkpoint, 1000, lstm_size, len(vocab), prime=\"Far\")\n",
    "print(samp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "* In this lesson we will be talking about hyperparameter.\n",
    "* And identifying possible starting values and intuitions for number of hyperparameters that we may have already come across , and that we'll need to know in your work with deep learning.\n",
    "> Hyperparameter can be divided into two general categories\n",
    ">* **Optimizer Hyperparameters** -- variable more related to the optimization and training process than to the model itself.\n",
    ">* This include the __learning_Rate__, the __minibatch size__ and __epochs__\n",
    ">* **Model Hyperparameters** -- These variable are more involved in the structue of the model.\n",
    ">* This inculde the __number of hidden layer and hidden units__, and __model specific hyperparameter for architectures__ like RNN.\n",
    "\n",
    "## Learning Rate\n",
    "* The single most important hyperparameter and one should always make sure that it has been tuned\n",
    "* If we have normalized our dataset than good starting point for learning rate will be 0.01\n",
    "* ** Read about learning rate decay and Adaptive Learning**\n",
    "* Adaptive Learning:\n",
    "    * This means not only decreasing the learning rate when needed, but also increasing it when it appears to be too low.\n",
    "    \n",
    "    \n",
    "## Minibatch Size\n",
    "\n",
    "* It has effect on the resource requirements of training process but also impacts training speed and number of iterations in a way that might not be as trivial as you may think.\n",
    "* stochastic training -- one observation at time \n",
    "    * do a forward pass \n",
    "    * calculate loss\n",
    "    * update weights \n",
    "    * and loop it for all observation\n",
    "* other extreme is batch training train with entire dataset.\n",
    "* **In practice, small minibatch sizes have more noise in their error calculation, and this noise is often helpful in preventing the training process from stopping at local minima on the error curve rather than the global minima that creates the best model.\n",
    "* SO while the computational boost incentivizes us to increase minibatch size, this (small batch size) practical algorithmic benefit incentivizes us to actually make it smaller.**\n",
    "* **Systematic evaluation paper titled Systematic evaluation of CNN advances on the image net. It shows that using the same learning rate the accuracy of model decrease with larger batch size**\n",
    "* This not only because of minibatch size but we need to change the learning rate when we increase the batch size.\n",
    "* If we do change the learning rate according to the minibatch size ... but we still see accuracy do decrease but slightly.\n",
    "> Good option for minibatch are :\n",
    "> [32,64,128,256]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Iterations\n",
    "To choose correct number of iteration the metric we should consider is **Validation Error**\n",
    "* So the idea is to train for as many epochs you till validation error **Decreases**\n",
    "* Luckily we can use a technique called early stopping to determine when to stop training a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Hidden Units/Layers\n",
    "* The main requirement here is to set a number of hidden units that is __large enough__.\n",
    "* For a neural network to learn approximately a function or a prediction task, it needs to have enough \"capacity\" to learn the function.\n",
    "* More complex the function more learning capacity model will need.\n",
    "* The number and architecture of hidden units ** is the main measure of model's learning capacity**\n",
    "* IF we provide too much capacity to the model than it tends to overfit the training data and there is huge difference between training accuracy and validation accuracy.\n",
    "    * we can also use L2 regularization and dropout.\n",
    "* As far as hidden unit is concern the more the better and then we can tame it with regularization and dropout.\n",
    "* If model is not training than add more hidden unit and then train it and track validation error.\n",
    "* For first hidden layer setting it to a larger than the number of inputs has been observed to be beneficial in many task.\n",
    "\n",
    "\n",
    "### Number of hidden layer\n",
    "* In pratice 3 hidden layer nn outperforms  2 hidden layer nn and going even deeper rarely helps.\n",
    "* The exception to this is CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Hyperparameters\n",
    "* Two main choice we need to make when we build a RNN.\n",
    "    * Choosing the cell type, so a long short term memory cell or a vanilla RNN cell or a gated recurrent unit cell,\n",
    "    * And how deep the model is. How many layer will we stack?\n",
    "\n",
    "* And since we need word embeddings if our inputs are words, we'll also look at embedding dimensionality.\n",
    "* GRU AND LSTM ARE EQUALLY GOOD NO ONE IS A CLEAR WINNER\n",
    "* Depth of 2 is actually better but further increasing it to three actually gives mixed results.(book sampling)\n",
    "* Another task like advanced speech recognition can show improvement with five and even layer often without LSTM cells\n",
    "* If our Rnn will be using words as inputs, then we'll need to choose a size for embedding vector.\n",
    "* How do we go about choosing this number?\n",
    "* Experimental results reporting a paper shows:\n",
    "    * Shows that the performance of some tasks improve the larger we make the embedding at least until a size of 200 \n",
    "    * In other task, however only marginal improvements are realised beyond the size of 50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings Intro\n",
    "## Word Embeddings\n",
    "\n",
    "* This is a deep neural method for representing data with a huge number of classes more efficiently. Embeddings greatly improve the ability of networks to learn from data of this sort by representing the data with lower dimensional vectors.\n",
    "\n",
    "* Word embeddings in particular are interesting because the networks are able to learn semantic relationships between words. For example, the embeddings will know that male equivalent of a queen is a king.\n",
    "\n",
    "* These word embeddings are learned using a model called Word2vec.\n",
    "\n",
    "* **\n",
    "* **\n",
    "* So when we are dealing with text and we split things up into words we tend to have tens of thousands of different words and a large dataset.\n",
    "* So when we these words as input the we're typically going to one-hot encoding them\n",
    "* we gonna have giant vectors which are quite long ( equal to vocab size) and one is set to zero and all other values zero.\n",
    "* And we are doing this multiplication which is computationaly complex something like $50,000 \\times 300$ different weight parameters in this giant matrix.\n",
    "* So this is just completely comptationally inefficient.\n",
    "* So to solve this problem we can use what are called embeddings.\n",
    "* Embedding are basically just a **shortcut for doing this matrix multiplication.**\n",
    "* **It's just the way that we actually get the value of hidden layer is different.**\n",
    "* So we do is actually just kind of skip matrix multiplication and just look up from a table what the values for this hidden layer is.\n",
    "* And we can do this because we are multiplying a one-hot encoded vector by a matrix, and we just get the row that corresponding to the element that was on(or 1).\n",
    "\n",
    "* **So then what we do is we actually tokenize our words. That means we convert them into integers and then we still have this, you know, embedding weight matrix that is goind from an input to a hidden layer.**\n",
    "* But now we are just calling it a lookup table becuase we literally just look up the row and this matrix that corresponds to our word.\n",
    "* And that is the values of our hidden layer.\n",
    "* So then the number of units in the hidden layer is called the **embedding dimension**.\n",
    "* And basically we just get a different vector, that is the size of our embedding dimension for each of our word.\n",
    "* So then, in this way we just completely skip this matrix multiplication.\n",
    "\n",
    "* All we doing is we're saying you know this word heart is now the integer 958 and then the matrix multiplication just gives us this row so we're just going to look up the 958 row nad we're going to use that as our hidden layer values.\n",
    "\n",
    "* Embedding look up table is just weights and the embedding layer is a hidden layer then this lookup is just a shortcut for the matrix mutiplication.\n",
    "\n",
    "* And this embedding matrix(or weight matrix) is updated using backpropagation like any other weight matrix.\n",
    "\n",
    "* And we can use them anywhere we have massive number of classes.\n",
    "\n",
    "* So what we gonna be doing in this notebook is looking at a particular type of model called __Word2vec__ that uses the embedding layer to get these like representations of these words from these vectros.\n",
    "\n",
    "* So each of these vectors in here is going to represent a word and it's going to actually **represent semantic meaning of those words**.\n",
    "* So word2vec is an algorithm that finds efficient representation by using vectors from the embedding layer. \n",
    "* And when its properly trained then the vector will contain sematic information.\n",
    "* So what is meant by semantic information is that words that words that show up in similar contexts, like colors like black white and red, they are going to show up in similar context and so those words are going to have similar representations and you know these vectors, the value of the vectors is going to be similar between these colors becuase they show up in similar contexts. \n",
    "\n",
    "\n",
    "\n",
    "#### Two Architecture of word2vec\n",
    "* __CBOW__ -- Continuous Bag of Words.\n",
    "* __Skip-gram__ \n",
    "* Skip-gram is going to be one that we're looking at because it has been shown to work better than CBOW\n",
    "\n",
    "* So in CBOW we take say two words before the target word(t-1,t-2) and two word after target word (t+1,t+2) and then try to predict the target word.\n",
    "    * So in **CBOW** we take context around the target word and then we try to predict the target word.\n",
    "    * So its like looking at a window in our text and we're trying to use that as the context and we're trying to predict the word that show up in the middle of this window \n",
    "    \n",
    "### Skip-gram\n",
    "* It is inverted of CBOW.\n",
    "* We are passing in some word and then we're trying to predict to predict the words that show up around it in the text.\n",
    "* So we're trying to predict like what context does this word appear in.\n",
    "* So in this way we're going to be training this network to understand the context and the meaning of words.\n",
    "* So for instance, again like black, white and red, they're going to show up in a similar context.They have similar like words surrounding it. And so then the passing in black and white and red is going to predict to the same words and the context.And so they're going to have similar projections.\n",
    "* They are going to have similar embedding vectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Word2vec\n",
    "* So in genral for training word2vec, we're going to have to want a really big dataset of text, so a lot of times is like Wikipedia articles, news article, booksm that sort of thing.\n",
    "* And this has been done for a whole bunch of different languages.\n",
    "\n",
    "* And here we are going to see how to train embedding layers so that we can use it in future models.\n",
    "* And now when we build our network and actually do this embedding lookup,we're passing in integers and we can do to lookup with these integers.\n",
    "* **\n",
    "* **\n",
    "* So there's a lot of words that show up in text that don't have a lot of like meaning or they don't provide a lot of context for the words that show up around it.\n",
    "* So like __the,of, and ,for,etc..__ you know like all these words just show up a lot but they don't really provide a lot of context for the words that are around them.\n",
    "* So what we can do is just get rid of some of these really frequent words.\n",
    "* And what it does it removes noise from our data and then it improves the training rate and we can get better representations in the end.\n",
    "\n",
    "* So this process of discarding free words is called the __subsampling__.\n",
    "* And the way do this is we calculate some frequnecy and we have a probability to drop each of these words. -- Overview\n",
    "\n",
    "* The **t** is a threshold parameter that basically lets us kind of set a threshold for how frequent a word needs to be for us to drop it with some probability.\n",
    "* So the idea is that for every word we calculate the frequency and then we calculate the probability that you would drop this word.\n",
    "\n",
    "* And so it's important to know that this is a probability.\n",
    "* So basically as we're scanning through and we see a word there's probabiltiy that we'll drop it or keep it and we want to make this like randomly unifrom over the entire datasets.\n",
    "* So when we are passing in batches, there is the equal probability that a word will dropped in the first bacth as there is in the last batch.\n",
    "* So the idea here is to go through int_words and then discard each word with the probability given in the notes and assign our new subsamples data to train words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsampling\n",
    "* Words that show up often such as \"the\",\"of\", and \"for\" don't provide much context to the nearby words. If we discard some of them, we can remove some of the noise from our dataset and in return get faster training and better representations. This process is called subsampling. For each word wi in training set , we'll discard it with probability given by \n",
    "\n",
    "$$ P(w_i) = 1 - \\sqrt{\\frac{t}{f(w_i)}} $$\n",
    "where t is a thershold parameter and f(wi) is the frequency of the word wi in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Batches\n",
    "* So now we are going to do actually start changing the data into batches.\n",
    "* So with skip-gram architecture, we are going to take words and then we're going to use the words the around that word in the text as the targets, right so to use as the context around whatever input word we have.\n",
    "* So basically for every words we gonna grab a window of words around it and that window's going to have some size **C**. So then what **Mikalov did is tey actually chose like some random range within this window.**\n",
    "* So the reason they did this is because __distant words__ are usually less related to whatever input word you have, than one those are close to it.\n",
    "* So basically we just want to kind of de-emphasize words that are further away as compared to words that are closer.\n",
    "\n",
    "* So then if we have a window C say like it's five, then what we're going to do is select some random number R that's in range of like one to C. \n",
    "* So basically we choosing like randomly a smaller window from your large window and then we have smaller window which is defined by R.\n",
    "* So basically we are just choosing randomly smaller window from our larger window.. and then we **just grab the words from the past and R words from the future**\n",
    "* And then we're going to use these as correct labels.\n",
    "* So what this does is we're basically always likely to get words that are right next to our current word, but we're less likely to get words that are further away from our current word.\n",
    "* And so what we are really doing is going to be training on the words that are closer to our current words, more often.\n",
    "* So what we are going to do here is actually implementing this.\n",
    "* So like we're going to get the target words.\n",
    "* So we get a pass in a string of words and then an index which is your current word and then we're going to grab a window from around the index and basically return all the target words in that window.\n",
    "\n",
    "* But we're going to be using ... like we're going to find some of this random range R and then only return that are in that smaller window R. And then once you have that written."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Batches\n",
    "* Now that our data is in good shape, we need to get into the proper form to pass it into our network. With the skip-gram architecture,for each words in the text , we want to grab all the words in the text, we want to grab all the text around that word in the window around that wors, with size C,\n",
    "\n",
    "* Since the more distant words are usually less related to the current word than those close to it, we give less weight to the distant words by smapling less from those words in our training examples.. If we choose C=5, for each training word we will select randomly a number R in range...... (1,c) and then ise R words from history and R words from the future of the current word as correct labels.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building of Network  -- Embedding Network.\n",
    "* So here we can see the genral structure of the network that we're going to build. \n",
    "* So we have our inputs, and as I said before this, we're not actually going to be doing this you know one hot encoding, we're going to be passing in integers, but so we're going to pass them to this __hidden layer which is our embedding layer.__\n",
    "* And the neuron are the linar neuron (no activation function) \n",
    "* And then a fully connected layer to a layer which have an output softmax layer.\n",
    "* So with the softmax layer we are going to predict our target words using this softmax layer.\n",
    "* When we train everything up, what's going to happen is that our, hidden layer is going to form these you know vector representation of the words that contain some semantic meaning. And thats what we are really interested in.\n",
    "* We only really care about these representations, that's what we're doing, it's like we're, changing these words into vectors.\n",
    "* So that means is tha when we're doing training we can just get rid of this softmax layer, that we don't really like care about it anymore. It's there to just train up the network..\n",
    "* The only thing we are really intrested in the weight between input and hidden layer.\n",
    "* So first thing we're going to do here is build the inputs.\n",
    "* We are going to create the inputs using tensor flow placeholder.\n",
    "* So we're going to be passing in integers and so then int32(datatype)\n",
    "* And the batches that we're passing in are going to have random size so we'll need to leave the batch size arbitrary, so we can set that as None.\n",
    "\n",
    "#### targets\n",
    "* So the target placeholder need to have a second dimension that you either set to One or None."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chris McCormik -- Word2Vec Tutorial\n",
    "## The Skip-Gram Model\n",
    "* Model Detail \n",
    "* So we can't input text in the model so will decode it in number and then maybe one-hot shot encoding...depnding on the problem..\n",
    "* So we build the vocabulary of the unique words and then accordingly put our matrix to one according to the word.\n",
    "* **The output of the network is also a single vector (with size of voabulary) for every word in vocabulary the probability that a randomly selected nearby word.**\n",
    "## The Hidden Layer\n",
    "* For our example we're going to say that we're learning words vector with **300 features**. So the hidden layer is going to be represented by a weight with **10,000** rows (vocab size) and 300 columns (one for every hidden neuron).\n",
    "* SO the end goal of all of this is really just to learn this hidden layer weight matrix the output layer we'll just toss when we're done!.\n",
    "* that one hot encoding vector is almost all zeros.... so if we multiply a $1\\times10000$ matrix it will just select the matrix row corresponding to the 1 in input vector.\n",
    "* So hidden layer is just a lookup table for our word.\n",
    "## the output layer\n",
    "* the $1\\times300$ word vector for \"ants\" then gets fed to the ouput layer. the output layer is a softmax regression here, but the gist of it is that each ouput neuron(one per word in vocabulary) will produce the value between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negative Sampling \n",
    "* For every example we give the network, we train it using the output from softmax layer. That means for each input, we are making very small changes to million of weights even though we only have one true example. This makes training the network very inefficient.\n",
    "* We can approximate the loss from the softmax layer by only updating a small subset of all the weight at once. **We'll update the weight for correct label, but only a small number of incorrect labels. This is called negative sampling.\n",
    "* Tensorflow function for above -- tf.nn.sampled_softmax_loss()**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis with an RNN\n",
    "* Here, we'll pass in words to an embedding layer. We need an embedding layer beacause we have tens of thousands of words, so we'll need more efficient representation for our input data than one-hot encoded vectors. * From the embedding layer, the new representation will be passes to LSTM cells. These will add recurrent connections to the network so we can include information about sequencce of words in the data. Finally, the LSTM cell will go to a sigmoid output layer here. We're using the sigmoid because we're trying to predict if this text has positive or negative sentiment. The output layer will just be a single unit then, with a sigmoid activation function.\n",
    "* We don't care about the sigmoid ouptus except for the very last one, we can ignore the rest. We'll calculate the cost from the ouptut of the last step and the training label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sentiment-network/reviews.txt','r') as f:\n",
    "    reviews = f.read()\n",
    "with open('sentiment-network/labels.txt','r') as f:\n",
    "    labels = f.read()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   \\nstory of a man who has unnatural feelings for a pig . starts out with a opening scene that is a terrific example of absurd comedy . a formal orchestra audience is turned into an insane  violent mob by the crazy chantings of it  s singers . unfortunately it stays absurd the whole time with no general narrative eventually making it just too off putting . even those from the era should be turned off . the cryptic dialogue would make shakespeare seem easy to a third grader . on a technical level it  s better than you might think with some good cinematography by future great vilmos zsigmond . future stars sally kirkland and frederic forrest can be seen briefly .  \\nhomelessness  or houselessness as george carlin stated  has been an issue for years but never a plan to help those on the street that were once considered human who did everything from going to school  work  or vote for the matter . most people think of the homeless as just a lost cause while worrying about things such as racism  the war on iraq  pressuring kids to succeed  technology  the elections  inflation  or worrying if they  ll be next to end up on the streets .  br    br   but what if y'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing \n",
    "* The first step when building a neural model is getting data into the proper form to feed into the network. Since we're using the embedding layers, we'll need to encode each word with an integer. We'll also want to clean the it up a bit.\n",
    "* we can see an example above  of the review data . We'll want to get rid of those periods. Also, you might notice that the reviews are delimited `\\n` as the delimeter. Then I can combined all the reviews back together into one big string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "all_text = ''.join([c for c in reviews if c not in punctuation])\n",
    "# above we are filtering our text and removing the punctutaion\n",
    "reviews = all_text.split('\\n')\n",
    "# above we are separating our text according to the review.\n",
    "\n",
    "\n",
    "all_text = ' '.join(reviews)\n",
    "# sO ALL TEXT IS CREATED SO WE CAN CREATE INT_TO_WORD ENCODING\n",
    "words = all_text.split()\n",
    "# and word is created so we can counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromwell high is a cartoon comedy  it ran at the same time as some other programs about school life  such as  teachers   my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers   the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students  when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled          at           high  a classic line inspector i  m here to sack one of your teachers  student welcome to bromwell high  i expect that many adults of my age think that bromwell high is far fetched  what a pity that it isn  t    story of a man who has unnatural feelings for a pig  starts out with a opening scene that is a terrific example of absurd comedy  a formal orchestra audience is turned into an insane  violent mo'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6020196"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74072"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25001"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding the words\n",
    "* The embedding lookup requires that we pass in integer to our network. The easiest way to do this is to create a dictionaries that map the words in vocabulary to integers. Then we can convert each of our reviews into intgers so they can be passed inp the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "vocab_frequency = Counter(words)\n",
    "vocab_frequency_sorted = sorted(vocab_frequency,key=vocab_frequency.get ,reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "vocab_to_int = {word:(index+1) for index,word in enumerate(vocab_frequency_sorted)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74072"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting the reviews to integers:\n",
    "reviews_ints = []\n",
    "\n",
    "\n",
    "for review in reviews:\n",
    "    temp_review = []\n",
    "    for word in review.split():\n",
    "        temp_review.append(vocab_to_int[word])\n",
    "    reviews_ints.append(temp_review)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimenting with programming and building ideas!!\n",
    "a = [(1,2),(2,3),(4,4)]\n",
    "l=[c for b in a  for c in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25001"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews_ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25001"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'story of a man who has unnatural feelings for a pig  starts out with a opening scene that is a terrific example of absurd comedy  a formal orchestra audience is turned into an insane  violent mob by the crazy chantings of it  s singers  unfortunately it stays absurd the whole time with no general narrative eventually making it just too off putting  even those from the era should be turned off  the cryptic dialogue would make shakespeare seem easy to a third grader  on a technical level it  s better than you might think with some good cinematography by future great vilmos zsigmond  future stars sally kirkland and frederic forrest can be seen briefly   '"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['story',\n",
       " 'of',\n",
       " 'a',\n",
       " 'man',\n",
       " 'who',\n",
       " 'has',\n",
       " 'unnatural',\n",
       " 'feelings',\n",
       " 'for',\n",
       " 'a',\n",
       " 'pig',\n",
       " 'starts',\n",
       " 'out',\n",
       " 'with',\n",
       " 'a',\n",
       " 'opening',\n",
       " 'scene',\n",
       " 'that',\n",
       " 'is',\n",
       " 'a',\n",
       " 'terrific',\n",
       " 'example',\n",
       " 'of',\n",
       " 'absurd',\n",
       " 'comedy',\n",
       " 'a',\n",
       " 'formal',\n",
       " 'orchestra',\n",
       " 'audience',\n",
       " 'is',\n",
       " 'turned',\n",
       " 'into',\n",
       " 'an',\n",
       " 'insane',\n",
       " 'violent',\n",
       " 'mob',\n",
       " 'by',\n",
       " 'the',\n",
       " 'crazy',\n",
       " 'chantings',\n",
       " 'of',\n",
       " 'it',\n",
       " 's',\n",
       " 'singers',\n",
       " 'unfortunately',\n",
       " 'it',\n",
       " 'stays',\n",
       " 'absurd',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'time',\n",
       " 'with',\n",
       " 'no',\n",
       " 'general',\n",
       " 'narrative',\n",
       " 'eventually',\n",
       " 'making',\n",
       " 'it',\n",
       " 'just',\n",
       " 'too',\n",
       " 'off',\n",
       " 'putting',\n",
       " 'even',\n",
       " 'those',\n",
       " 'from',\n",
       " 'the',\n",
       " 'era',\n",
       " 'should',\n",
       " 'be',\n",
       " 'turned',\n",
       " 'off',\n",
       " 'the',\n",
       " 'cryptic',\n",
       " 'dialogue',\n",
       " 'would',\n",
       " 'make',\n",
       " 'shakespeare',\n",
       " 'seem',\n",
       " 'easy',\n",
       " 'to',\n",
       " 'a',\n",
       " 'third',\n",
       " 'grader',\n",
       " 'on',\n",
       " 'a',\n",
       " 'technical',\n",
       " 'level',\n",
       " 'it',\n",
       " 's',\n",
       " 'better',\n",
       " 'than',\n",
       " 'you',\n",
       " 'might',\n",
       " 'think',\n",
       " 'with',\n",
       " 'some',\n",
       " 'good',\n",
       " 'cinematography',\n",
       " 'by',\n",
       " 'future',\n",
       " 'great',\n",
       " 'vilmos',\n",
       " 'zsigmond',\n",
       " 'future',\n",
       " 'stars',\n",
       " 'sally',\n",
       " 'kirkland',\n",
       " 'and',\n",
       " 'frederic',\n",
       " 'forrest',\n",
       " 'can',\n",
       " 'be',\n",
       " 'seen',\n",
       " 'briefly']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[1].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   63,     4,     3,   125,    36,    47,  7472,  1395,    16,\n",
       "           3,  4181,   505,    45,    17,     3,   622,   134,    12,\n",
       "           6,     3,  1279,   457,     4,  1721,   207,     3, 10624,\n",
       "        7373,   300,     6,   667,    83,    35,  2116,  1086,  2989,\n",
       "          34,     1,   898, 46417,     4,     8,    13,  5096,   464,\n",
       "           8,  2656,  1721,     1,   221,    57,    17,    58,   794,\n",
       "        1297,   832,   228,     8,    43,    98,   123,  1469,    59,\n",
       "         147,    38,     1,   963,   142,    29,   667,   123,     1,\n",
       "       13584,   410,    61,    94,  1774,   306,   755,     5,     3,\n",
       "         819, 10396,    22,     3,  1724,   635,     8,    13,   128,\n",
       "          73,    21,   233,   102,    17,    49,    50,   617,    34,\n",
       "         682,    85, 28785, 28786,   682,   374,  3341, 11398,     2,\n",
       "       16371,  7946,    51,    29,   108,  3324])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(reviews_ints[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n",
      "114\n"
     ]
    }
   ],
   "source": [
    "print(len(reviews[1].split())) ## other wise it would have taken the spaces as character too!\n",
    "print(len(reviews_ints[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding the labels\n",
    "* Our labels are \"positive\" or \"negative\". To use them we need to encode them in 1 and 0 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_new = labels.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [1 if label == \"positive\"  else 0 for label in labels_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " ...]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25001"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_lens = Counter([len(x) for x in reviews_ints])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-length reviews: 1\n",
      "Maximum review lenght: 2514\n"
     ]
    }
   ],
   "source": [
    "print(\"Zero-length reviews: {}\".format(review_lens[0]))\n",
    "print(\"Maximum review lenght: {}\".format(max(review_lens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Okay, a couple issues here. We seem to have one review with zero length. And, the maximum review is way too many steps for our Rnn. Let's truncate to 200 steps, we'll pad with 0s. For reviews longer than 200, we can truncate them to the first 200 characters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter out that review with 0 length\n",
    "zip_review_labels = [review for review in zip(reviews_ints,labels) if len(review[0]) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_ints = []\n",
    "labels= []\n",
    "for zip_review in zip_review_labels:\n",
    "    reviews_ints.append(zip_review[0])\n",
    "    labels.append(zip_review[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-length reviews: 0\n",
      "Maximum review length: 2514\n",
      "Minimum review length: 10\n"
     ]
    }
   ],
   "source": [
    "review_lens = Counter([len(x) for x in reviews_ints])\n",
    "print(\"Zero-length reviews: {}\".format(review_lens[0]))\n",
    "print(\"Maximum review length: {}\".format(max(review_lens)))\n",
    "print(\"Minimum review length: {}\".format(min(review_lens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Exercise:** Now, we have to create an array features that contains the data we'll pass to the network. The data should come from `reviews_ints`, since we want to feed intgers to the networks. Each row should be 200 element long.For reviews shorter than 200 words, left pad with 0s. For reviews longer than 200, we use on the first 200 words as features vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4,5,6,7,8,9]\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length =200\n",
    "new_reviews_ints = []\n",
    "for review_int in reviews_ints:\n",
    "    length = len(review_int)\n",
    "    if length >= seq_length:\n",
    "        temp_review = review_int[:seq_length]\n",
    "    else :\n",
    "        factor = seq_length-len(review_int)\n",
    "        temp_review = np.zeros((seq_length))\n",
    "        temp_review[factor:seq_length] = review_int\n",
    "    new_reviews_ints.append(temp_review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = np.array(new_reviews_ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = Counter([len(f) for f in features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({200: 25000})"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length\n",
    "## So all the features have a length of 200\n",
    "# YAY!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0, 21025,   308,     6,\n",
       "            3,  1050,   207,     8,  2138,    32,     1,   171,    57,\n",
       "           15,    49,    81,  5785,    44,   382,   110,   140,    15,\n",
       "         5194,    60,   154,     9,     1,  4975,  5852,   475,    71,\n",
       "            5,   260,    12, 21025,   308,    13,  1978,     6,    74,\n",
       "         2395],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,    63,     4,     3,   125,\n",
       "           36,    47,  7472,  1395,    16,     3,  4181,   505,    45,\n",
       "           17],\n",
       "       [22382,    42, 46418,    15,   706, 17139,  3389,    47,    77,\n",
       "           35,  1819,    16,   154,    19,   114,     3,  1305,     5,\n",
       "          336,   147,    22,     1,   857,    12,    70,   281,  1168,\n",
       "          399,    36,   120,   283,    38,   169,     5,   382,   158,\n",
       "           42,  2269,    16,     1,   541,    90,    78,   102,     4,\n",
       "            1,  3244,    15,    43,     3,   407,  1068,   136,  8055,\n",
       "           44,   182,   140,    15,  3043,     1,   320,    22,  4818,\n",
       "        26224,   346,     5,  3090,  2092,     1, 18839, 17939,    42,\n",
       "         8055,    46,    33,   236,    29,   370,     5,   130,    56,\n",
       "           22,     1,  1928,     7,     7,    19,    48,    46,    21,\n",
       "           70,   344,     3,  2099,     5,   408,    22,     1,  1928,\n",
       "           16],\n",
       "       [ 4505,   505,    15,     3,  3342,   162,  8312,  1652,     6,\n",
       "         4819,    56,    17,  4504,  5616,   140, 11725,     5,   996,\n",
       "         4919,  2933,  4462,   566,  1201,    36,     6,  1518,    96,\n",
       "            3,   744,     4, 26225,    13,     5,    27,  3461,     9,\n",
       "        10625,     4,     8,   111,  3013,     5,     1,  1027,    15,\n",
       "            3,  4390,    82,    22,  2049,     6,  4462,   538,  2764,\n",
       "         7073, 37443,    41,   463,     1,  8312, 46419,   302,   123,\n",
       "           15,  4221,    19,  1667,   922,     1,  1652,     6,  6129,\n",
       "        19871,    34,     1,   980,  1751, 22383,   646, 24104,    27,\n",
       "          106, 11726,    13, 14045, 15097, 17940,  2457,   466, 21027,\n",
       "           36,  3266,     1,  6365,  1020,    45,    17,  2695,  2499,\n",
       "           33],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,   520,   119,   113,    34,\n",
       "        16372,  1816,  3737,   117,   885, 21030,   721,    10,    28,\n",
       "          124,   108,     2,   115,   137,     9,  1623,  7691,    26,\n",
       "          330,     5,   589,     1,  6130,    22,   386,     6,     3,\n",
       "          349,    15,    50,    15,   231,     9,  7473, 11399,     1,\n",
       "          191,    22,  8966,     6,    82,   880,   101,   111,  3584,\n",
       "            4],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           11,    20,  3637,   141,    10,   422,    23,   272,    60,\n",
       "         4355,    22,    32,    84,  3286,    22,     1,   172,     4,\n",
       "            1,   952,   507,    11,  4977,  5361,     5,   574,     4,\n",
       "         1155,    54,    53,  5304,     1,   261,    17,    41,   952,\n",
       "          125,    59,     1,   711,   137,   379,   626,    15,   111,\n",
       "         1509],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,    11,     6,   692,     1,    90,\n",
       "         2156,    20, 11728,     1,  2818,  5195,   249,    92,  3006,\n",
       "            8,   126,    24,   200,     3,   802,   634,     4, 22382,\n",
       "         1001],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,   786,   295,    10,   122,    11,     6,   419,\n",
       "            5,    29,    35,   482,    20,    19,  1281,    33,   142,\n",
       "           28,  2657,    45,  1840,    32,     1,  2778,    37,    78,\n",
       "           97,  2436,    67,  3950,    45,     2,    24,   105,   256,\n",
       "            1,   134,  1571,     2, 12399,   451,    14,   319,    11,\n",
       "           63,     6,    98,  1321,     5,   105,     1,  3767,     4,\n",
       "            3],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,    11,     6,\n",
       "           24,     1,   779,  3687,  2818,    20,     8,    14,    74,\n",
       "          325,  2730,    73,    90,     4,    27,    99,     2,   165,\n",
       "           68],\n",
       "       [   54,    10,    14,   116,    60,   798,   552,    71,   364,\n",
       "            5,     1,   730,     5,    66,  8057,     8,    14,    30,\n",
       "            4,   109,    99,    10,   293,    17,    60,   798,    19,\n",
       "           11,    14,     1,    64,    30,    69,  2500,    45,     4,\n",
       "          234,    93,    10,    68,   114,   108,  8057,   363,    43,\n",
       "         1009,     2,    10,    97,    28,  1431,    45,     1,   357,\n",
       "            4,    60,   110,   205,     8,    48,     3,  1929, 10880,\n",
       "            2,  2124,   354,   412,     4,    13,  6609,     2,  2974,\n",
       "         5148,  2125,  1366,     6,    30,     4,    60,   502,   876,\n",
       "           19,  8057,     6,    34,   227,     1,   247,   412,     4,\n",
       "          582,     4,    27,   599,     9,     1, 13586,   396,     4,\n",
       "        14047]], dtype=int32)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:10,:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, Validation, Test\n",
    "With our data in nice shape, we'll split it into training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "split_frac = 0.8\n",
    "val_x,train_x,val_y,train_y = train_test_split(features,labels,test_size=split_frac)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 200)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 200)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_x,test_x,val_y,test_y = train_test_split(val_x,val_y,test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(20000, 200) \n",
      "Validation set: \t(2500, 200) \n",
      "Test set: \t\t(2500, 200)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the graph\n",
    "Here, we'll build the graph. First up, defining the hyperparameters.\n",
    "* `lstm_size`:Number of units in the hidden layer in the LSTM cells. Usually larger is better performance wise. Common values are 129,256,512,etc.\n",
    "* `lstm_layer`:Number of LSTM layers in the network. I'd start with 1,then add more If I'm underfitting.\n",
    "* `batch_size`:The number if reviews to feed the network in one training pass. Typically this should be set as high as we can go without running out of memeory.\n",
    "* `learning_rate`:Learning Rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_size = 256\n",
    "lstm_layers =1\n",
    "batch_size = 500\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Placeholder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/unnatsingh/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = len(vocab_to_int)+1 # Adding 1 because for padding zero is used\n",
    "\n",
    "#Create the graph object\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.int32,[None,None],name=\"inputs\")\n",
    "    labels_ =tf.placeholder(tf.int32,[None,None],name=\"labels\")\n",
    "    keep_prob = tf.placeholder(dtype=tf.float32,name=\"keep_prob\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_size = 300\n",
    "with graph.as_default():\n",
    "    embedding=tf.Variable(tf.random_uniform([n_words,embed_size],-1,1))\n",
    "    embed = tf.nn.embedding_lookup(embedding,inputs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    def build_cell(lstm_size,keep_prob):\n",
    "        lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "        drop = tf.contrib.rnn.DropoutWrapper(lstm,output_keep_prob=keep_prob)\n",
    "        return drop\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([(build_cell(lstm_size,keep_prob)) for _ in range(lstm_layers)])\n",
    "    initial_state = cell.zero_state(batch_size,tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    outputs, final_state = tf.nn.dynamic_rnn(cell,embed,\n",
    "                                             initial_state=initial_state)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "We only care about the final output, we'll be using that as our sentiment\n",
    "prediction. So we need to grab the last output with outputs[:,-1], the calculate the cost form `labels_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    predictions = tf.contrib.layers.fully_connected(outputs[:,-1],1,activation_fn = tf.sigmoid)\n",
    "    cost = tf.losses.mean_squared_error(labels_,predictions)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation accuracy\n",
    "Here we can add a few nodes to calculate the accuracy which we'll use in the validation pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    \n",
    "    correct_pred = tf.equal(tf.cast(tf.round(predictions),tf.int32),labels_)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching \n",
    "This is a simple function for returning batches from our data. First it removes data such that we only have full batches. Then it iterates through x and y arrays and returns slices out of those arrays with size `[batch_size]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(x,y,batch_size=100):\n",
    "    n_batches = len(x)//batch_size\n",
    "    full_batches = n_batches*batch_size\n",
    "    x,y = x[:full_batches],y[:full_batches]\n",
    "    for ii in range(0,len(x),batch_size):\n",
    "        yield x[ii:ii+batch_size], y[ii:ii+batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/10 Iterations: 5 Train Loss: 0.243\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-227-46119849922f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                    initial_state:state}\n\u001b[1;32m     15\u001b[0m             loss,state,_ = sess.run([cost,final_state,optimizer],\n\u001b[0;32m---> 16\u001b[0;31m                                     feed_dict=feed)\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 print(\"Epoch: {}/{}\".format(e,epochs),\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "with graph.as_default():\n",
    "    saver=tf.train.Saver()\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    state = sess.run(initial_state)\n",
    "    iterations = 1\n",
    "    for e in range(epochs):\n",
    "        for x,y in get_batches(train_x,train_y,batch_size):\n",
    "            y = np.array(y).reshape([-1,1])\n",
    "            feed = {inputs_:x,\n",
    "                   labels_: y,\n",
    "                   keep_prob:0.5,\n",
    "                   initial_state:state}\n",
    "            loss,state,_ = sess.run([cost,final_state,optimizer],\n",
    "                                    feed_dict=feed)\n",
    "            if iterations%5==0:\n",
    "                print(\"Epoch: {}/{}\".format(e,epochs),\n",
    "                     \"Iterations: {}\".format(iterations),\n",
    "                     \"Train Loss: {:.3f}\".format(loss))\n",
    "                \n",
    "            if iterations%25 == 0:\n",
    "                val_acc =[]\n",
    "                val_state = sess.run(cell.zero_state(batch_size,tf.float32))\n",
    "                for x,y in get_batches(val_x,val_y,batch_size):\n",
    "                    feed = {inputs_:x,\n",
    "                           targets:y[:,None],\n",
    "                           keep_prob:1.0,\n",
    "                           initial_state:val_state}\n",
    "                    batch_acc,val_state = sess.run([accuracy,final_state],\n",
    "                                                  feed_dict=feed)\n",
    "                    val_acc.append(batch_acc)\n",
    "                print(\"Val acc {:.3f}\".format(np.mean(val_acc)))\n",
    "                    ## above we are doing the mean of the batches beacuse we \n",
    "                    ## are also averaging all the accuracy across all the \n",
    "                    ## batches\n",
    "            iterations +=1\n",
    "        saver.save(sess,\"sentiments.cpkt\")\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1335496a0>]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "a = np.random.randint(1,100,size=1000)\n",
    "plt.plot(np.log(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13352f3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
