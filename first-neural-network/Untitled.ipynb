{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/unnatsingh/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train,y_train),(X_test,y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from keras.datasets import boston_housing\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-51d66366d1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig = plt.figure(figsize=(20,20))\n",
    "for i in range(6):\n",
    "    ax = fig.add_subplot(1,6,i+1,xticks=[],yticks=[])\n",
    "    ax.imshow(X_train[i],cmap=\"gray\")\n",
    "    ax.set_title(str(y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype(\"float32\")/255\n",
    "X_test = X_test.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#OnehotLabel\n",
    "import pandas as pd\n",
    "y_train_df = pd.get_dummies(y_train)\n",
    "y_train=np.array(pd.get_dummies(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Reshaping X_train\n",
    "X_train_matrix = X_train.reshape(60000,-1)\n",
    "X_train_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 20)                280       \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model in Lecture\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout,Dense\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(20,input_dim=x_train.shape[1],activation=\"relu\"))\n",
    "#model1.add(Dense(6,activation=\"relu\"))\n",
    "#model1.add(Dense(1,activation=\"relu\"))\n",
    "#model1.add(Dense(10,activation=\"relu\"))\n",
    "model1.add(Dense(1))\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_flatten = X_test.reshape(X_test.shape[0],-1)\n",
    "y_test_one_hot = np.array(pd.get_dummies(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "model1.compile(loss='mean_squared_error', optimizer=\"adam\")\n",
    "#model1.compile(loss=\"mean_squared_error\",optimizer=\"sgd\",metrics=[\"accuracy\"])\n",
    "#score_1 = model1.evaluate(x_test,y_test)\n",
    "#100*score_1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 4791.8574\n",
      "Epoch 00001: val_loss improved from inf to 3051.34692, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 4668.1861 - val_loss: 3051.3469\n",
      "Epoch 2/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 4045.8965\n",
      "Epoch 00002: val_loss improved from 3051.34692 to 2212.76758, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 147us/step - loss: 3647.7879 - val_loss: 2212.7676\n",
      "Epoch 3/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 3197.0300\n",
      "Epoch 00003: val_loss improved from 2212.76758 to 1598.29102, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 147us/step - loss: 2795.9917 - val_loss: 1598.2910\n",
      "Epoch 4/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 1609.3440\n",
      "Epoch 00004: val_loss improved from 1598.29102 to 1180.34485, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 141us/step - loss: 2155.3319 - val_loss: 1180.3448\n",
      "Epoch 5/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 1954.8530\n",
      "Epoch 00005: val_loss improved from 1180.34485 to 921.80499, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 150us/step - loss: 1732.9157 - val_loss: 921.8050\n",
      "Epoch 6/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 923.2890\n",
      "Epoch 00006: val_loss improved from 921.80499 to 778.58795, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 169us/step - loss: 1428.0752 - val_loss: 778.5880\n",
      "Epoch 7/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 1395.4740\n",
      "Epoch 00007: val_loss improved from 778.58795 to 704.34198, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 164us/step - loss: 1270.2735 - val_loss: 704.3420\n",
      "Epoch 8/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 1142.4644\n",
      "Epoch 00008: val_loss improved from 704.34198 to 662.66931, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 177us/step - loss: 1154.0669 - val_loss: 662.6693\n",
      "Epoch 9/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 1160.8351\n",
      "Epoch 00009: val_loss improved from 662.66931 to 628.54114, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 164us/step - loss: 1079.0089 - val_loss: 628.5411\n",
      "Epoch 10/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 766.4631\n",
      "Epoch 00010: val_loss improved from 628.54114 to 588.83868, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 161us/step - loss: 998.8765 - val_loss: 588.8387\n",
      "Epoch 11/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 760.4055\n",
      "Epoch 00011: val_loss improved from 588.83868 to 541.89740, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 183us/step - loss: 933.2702 - val_loss: 541.8974\n",
      "Epoch 12/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 837.7850\n",
      "Epoch 00012: val_loss improved from 541.89740 to 491.66455, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 148us/step - loss: 859.3001 - val_loss: 491.6646\n",
      "Epoch 13/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 769.5403\n",
      "Epoch 00013: val_loss improved from 491.66455 to 442.99542, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 164us/step - loss: 788.2473 - val_loss: 442.9954\n",
      "Epoch 14/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 663.8713\n",
      "Epoch 00014: val_loss improved from 442.99542 to 400.43347, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 157us/step - loss: 722.7848 - val_loss: 400.4335\n",
      "Epoch 15/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 486.1408\n",
      "Epoch 00015: val_loss improved from 400.43347 to 367.39136, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 142us/step - loss: 660.3022 - val_loss: 367.3914\n",
      "Epoch 16/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 898.0662\n",
      "Epoch 00016: val_loss improved from 367.39136 to 342.67850, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 134us/step - loss: 618.6799 - val_loss: 342.6785\n",
      "Epoch 17/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 865.5008\n",
      "Epoch 00017: val_loss improved from 342.67850 to 325.21179, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 149us/step - loss: 580.0987 - val_loss: 325.2118\n",
      "Epoch 18/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 427.6117\n",
      "Epoch 00018: val_loss improved from 325.21179 to 312.92505, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 164us/step - loss: 543.4479 - val_loss: 312.9250\n",
      "Epoch 19/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 518.7274\n",
      "Epoch 00019: val_loss improved from 312.92505 to 302.46942, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 145us/step - loss: 518.0127 - val_loss: 302.4694\n",
      "Epoch 20/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 459.1644\n",
      "Epoch 00020: val_loss improved from 302.46942 to 292.93158, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 160us/step - loss: 494.2470 - val_loss: 292.9316\n",
      "Epoch 21/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 507.6626\n",
      "Epoch 00021: val_loss improved from 292.93158 to 283.33163, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 153us/step - loss: 473.2641 - val_loss: 283.3316\n",
      "Epoch 22/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 483.1255\n",
      "Epoch 00022: val_loss improved from 283.33163 to 273.70947, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 159us/step - loss: 451.7622 - val_loss: 273.7095\n",
      "Epoch 23/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 506.4307\n",
      "Epoch 00023: val_loss improved from 273.70947 to 264.37469, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 141us/step - loss: 432.2099 - val_loss: 264.3747\n",
      "Epoch 24/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 412.3498\n",
      "Epoch 00024: val_loss improved from 264.37469 to 255.38663, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 153us/step - loss: 412.0118 - val_loss: 255.3866\n",
      "Epoch 25/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 502.8481\n",
      "Epoch 00025: val_loss improved from 255.38663 to 246.61307, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 155us/step - loss: 396.1040 - val_loss: 246.6131\n",
      "Epoch 26/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 466.4313\n",
      "Epoch 00026: val_loss improved from 246.61307 to 238.25842, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 134us/step - loss: 379.1531 - val_loss: 238.2584\n",
      "Epoch 27/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 340.0890\n",
      "Epoch 00027: val_loss improved from 238.25842 to 230.19905, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 145us/step - loss: 362.8948 - val_loss: 230.1991\n",
      "Epoch 28/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 429.9160\n",
      "Epoch 00028: val_loss improved from 230.19905 to 222.23216, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 161us/step - loss: 348.6748 - val_loss: 222.2322\n",
      "Epoch 29/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 350.9949\n",
      "Epoch 00029: val_loss improved from 222.23216 to 214.51720, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 220us/step - loss: 333.9874 - val_loss: 214.5172\n",
      "Epoch 30/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 374.4118\n",
      "Epoch 00030: val_loss improved from 214.51720 to 206.97545, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 164us/step - loss: 320.7088 - val_loss: 206.9754\n",
      "Epoch 31/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 305.0776\n",
      "Epoch 00031: val_loss improved from 206.97545 to 199.59911, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 158us/step - loss: 307.8605 - val_loss: 199.5991\n",
      "Epoch 32/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 242.1504\n",
      "Epoch 00032: val_loss improved from 199.59911 to 192.64288, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 126us/step - loss: 295.1103 - val_loss: 192.6429\n",
      "Epoch 33/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 269.8819\n",
      "Epoch 00033: val_loss improved from 192.64288 to 186.06665, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 129us/step - loss: 283.3483 - val_loss: 186.0667\n",
      "Epoch 34/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 265.6841\n",
      "Epoch 00034: val_loss improved from 186.06665 to 179.72681, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 125us/step - loss: 272.0634 - val_loss: 179.7268\n",
      "Epoch 35/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 282.1287\n",
      "Epoch 00035: val_loss improved from 179.72681 to 173.50716, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 122us/step - loss: 261.6580 - val_loss: 173.5072\n",
      "Epoch 36/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 215.3121\n",
      "Epoch 00036: val_loss improved from 173.50716 to 167.60486, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 134us/step - loss: 250.5568 - val_loss: 167.6049\n",
      "Epoch 37/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 280.1606\n",
      "Epoch 00037: val_loss improved from 167.60486 to 161.85107, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 142us/step - loss: 241.1704 - val_loss: 161.8511\n",
      "Epoch 38/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 240.9215\n",
      "Epoch 00038: val_loss improved from 161.85107 to 156.49452, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 145us/step - loss: 231.4868 - val_loss: 156.4945\n",
      "Epoch 39/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 227.2938\n",
      "Epoch 00039: val_loss improved from 156.49452 to 151.39018, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 157us/step - loss: 222.3162 - val_loss: 151.3902\n",
      "Epoch 40/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 159.1290\n",
      "Epoch 00040: val_loss improved from 151.39018 to 146.65811, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 135us/step - loss: 212.7104 - val_loss: 146.6581\n",
      "Epoch 41/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 203.4579\n",
      "Epoch 00041: val_loss improved from 146.65811 to 142.26514, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 169us/step - loss: 204.4674 - val_loss: 142.2651\n",
      "Epoch 42/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 163.8351\n",
      "Epoch 00042: val_loss improved from 142.26514 to 137.94058, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 148us/step - loss: 195.9639 - val_loss: 137.9406\n",
      "Epoch 43/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 242.5043\n",
      "Epoch 00043: val_loss improved from 137.94058 to 133.71428, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 162us/step - loss: 189.3092 - val_loss: 133.7143\n",
      "Epoch 44/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 145.7938\n",
      "Epoch 00044: val_loss improved from 133.71428 to 129.80185, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 188us/step - loss: 180.5908 - val_loss: 129.8018\n",
      "Epoch 45/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 162.2556\n",
      "Epoch 00045: val_loss improved from 129.80185 to 125.93993, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 190us/step - loss: 173.6102 - val_loss: 125.9399\n",
      "Epoch 46/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 192.6573\n",
      "Epoch 00046: val_loss improved from 125.93993 to 122.31021, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 159us/step - loss: 167.4164 - val_loss: 122.3102\n",
      "Epoch 47/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 144.4007\n",
      "Epoch 00047: val_loss improved from 122.31021 to 119.02117, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 126us/step - loss: 160.2786 - val_loss: 119.0212\n",
      "Epoch 48/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 176.4644\n",
      "Epoch 00048: val_loss improved from 119.02117 to 115.99638, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 151us/step - loss: 154.4327 - val_loss: 115.9964\n",
      "Epoch 49/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 144.9240\n",
      "Epoch 00049: val_loss improved from 115.99638 to 113.20856, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 142us/step - loss: 148.9045 - val_loss: 113.2086\n",
      "Epoch 50/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 138.7209\n",
      "Epoch 00050: val_loss improved from 113.20856 to 110.65704, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 171us/step - loss: 143.1276 - val_loss: 110.6570\n",
      "Epoch 51/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 143.7502\n",
      "Epoch 00051: val_loss improved from 110.65704 to 108.27233, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 208us/step - loss: 137.8948 - val_loss: 108.2723\n",
      "Epoch 52/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 114.8423\n",
      "Epoch 00052: val_loss improved from 108.27233 to 106.08103, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 180us/step - loss: 133.1531 - val_loss: 106.0810\n",
      "Epoch 53/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 146.9484\n",
      "Epoch 00053: val_loss improved from 106.08103 to 103.83990, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 196us/step - loss: 128.8425 - val_loss: 103.8399\n",
      "Epoch 54/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 143.9307\n",
      "Epoch 00054: val_loss improved from 103.83990 to 101.79274, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 193us/step - loss: 124.3949 - val_loss: 101.7927\n",
      "Epoch 55/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 141.4609\n",
      "Epoch 00055: val_loss improved from 101.79274 to 99.81054, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 159us/step - loss: 120.4838 - val_loss: 99.8105\n",
      "Epoch 56/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 106.8124\n",
      "Epoch 00056: val_loss improved from 99.81054 to 98.09985, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 168us/step - loss: 116.3023 - val_loss: 98.0999\n",
      "Epoch 57/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 112.4277\n",
      "Epoch 00057: val_loss improved from 98.09985 to 96.32892, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 175us/step - loss: 112.8075 - val_loss: 96.3289\n",
      "Epoch 58/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 117.4348\n",
      "Epoch 00058: val_loss improved from 96.32892 to 94.72807, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 222us/step - loss: 109.3245 - val_loss: 94.7281\n",
      "Epoch 59/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 114.9387\n",
      "Epoch 00059: val_loss improved from 94.72807 to 93.34276, saving model to ./best_weight_boston.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 0s 166us/step - loss: 106.1189 - val_loss: 93.3428\n",
      "Epoch 60/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 124.9605\n",
      "Epoch 00060: val_loss improved from 93.34276 to 91.90302, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 151us/step - loss: 103.3511 - val_loss: 91.9030\n",
      "Epoch 61/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 100.8513\n",
      "Epoch 00061: val_loss improved from 91.90302 to 90.69523, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 153us/step - loss: 100.2759 - val_loss: 90.6952\n",
      "Epoch 62/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 80.3053\n",
      "Epoch 00062: val_loss improved from 90.69523 to 89.58968, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 192us/step - loss: 97.5928 - val_loss: 89.5897\n",
      "Epoch 63/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 101.5234\n",
      "Epoch 00063: val_loss improved from 89.58968 to 88.57913, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 204us/step - loss: 95.3815 - val_loss: 88.5791\n",
      "Epoch 64/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 87.6888\n",
      "Epoch 00064: val_loss improved from 88.57913 to 87.61768, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 179us/step - loss: 93.1069 - val_loss: 87.6177\n",
      "Epoch 65/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 74.6829\n",
      "Epoch 00065: val_loss improved from 87.61768 to 86.69964, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 181us/step - loss: 91.0175 - val_loss: 86.6996\n",
      "Epoch 66/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 77.2613\n",
      "Epoch 00066: val_loss improved from 86.69964 to 85.87247, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 149us/step - loss: 88.9570 - val_loss: 85.8725\n",
      "Epoch 67/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 81.3970\n",
      "Epoch 00067: val_loss improved from 85.87247 to 84.98103, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 137us/step - loss: 87.1439 - val_loss: 84.9810\n",
      "Epoch 68/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 93.1026\n",
      "Epoch 00068: val_loss improved from 84.98103 to 84.02757, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 126us/step - loss: 85.4147 - val_loss: 84.0276\n",
      "Epoch 69/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 68.5667\n",
      "Epoch 00069: val_loss improved from 84.02757 to 83.13053, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 149us/step - loss: 83.7054 - val_loss: 83.1305\n",
      "Epoch 70/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 108.8092\n",
      "Epoch 00070: val_loss improved from 83.13053 to 82.30360, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 128us/step - loss: 82.4188 - val_loss: 82.3036\n",
      "Epoch 71/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 70.3927\n",
      "Epoch 00071: val_loss improved from 82.30360 to 81.80060, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 172us/step - loss: 80.6085 - val_loss: 81.8006\n",
      "Epoch 72/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 78.0428\n",
      "Epoch 00072: val_loss improved from 81.80060 to 81.26911, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 196us/step - loss: 79.3131 - val_loss: 81.2691\n",
      "Epoch 73/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 75.4706\n",
      "Epoch 00073: val_loss improved from 81.26911 to 80.81602, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 180us/step - loss: 78.0628 - val_loss: 80.8160\n",
      "Epoch 74/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 79.6479\n",
      "Epoch 00074: val_loss improved from 80.81602 to 80.24850, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 173us/step - loss: 76.7351 - val_loss: 80.2485\n",
      "Epoch 75/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 67.2230\n",
      "Epoch 00075: val_loss improved from 80.24850 to 79.57196, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 151us/step - loss: 75.5623 - val_loss: 79.5720\n",
      "Epoch 76/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 65.4219\n",
      "Epoch 00076: val_loss improved from 79.57196 to 78.95841, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 160us/step - loss: 74.4398 - val_loss: 78.9584\n",
      "Epoch 77/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 75.6333\n",
      "Epoch 00077: val_loss improved from 78.95841 to 78.30044, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 134us/step - loss: 73.3860 - val_loss: 78.3004\n",
      "Epoch 78/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 70.2419\n",
      "Epoch 00078: val_loss improved from 78.30044 to 77.77390, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 138us/step - loss: 72.4804 - val_loss: 77.7739\n",
      "Epoch 79/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 74.6589\n",
      "Epoch 00079: val_loss improved from 77.77390 to 77.30625, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 147us/step - loss: 71.5358 - val_loss: 77.3063\n",
      "Epoch 80/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 76.8722\n",
      "Epoch 00080: val_loss improved from 77.30625 to 76.98649, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 177us/step - loss: 70.6340 - val_loss: 76.9865\n",
      "Epoch 81/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 72.7310\n",
      "Epoch 00081: val_loss improved from 76.98649 to 76.74413, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 230us/step - loss: 69.7973 - val_loss: 76.7441\n",
      "Epoch 82/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 68.8189\n",
      "Epoch 00082: val_loss improved from 76.74413 to 76.45657, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 202us/step - loss: 69.0852 - val_loss: 76.4566\n",
      "Epoch 83/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 58.8619\n",
      "Epoch 00083: val_loss improved from 76.45657 to 76.09095, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 171us/step - loss: 68.3307 - val_loss: 76.0910\n",
      "Epoch 84/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 68.0433\n",
      "Epoch 00084: val_loss improved from 76.09095 to 75.61866, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 156us/step - loss: 67.5936 - val_loss: 75.6187\n",
      "Epoch 85/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 50.0280\n",
      "Epoch 00085: val_loss improved from 75.61866 to 75.31020, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 163us/step - loss: 66.9539 - val_loss: 75.3102\n",
      "Epoch 86/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 81.4753\n",
      "Epoch 00086: val_loss improved from 75.31020 to 74.78423, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 146us/step - loss: 66.3161 - val_loss: 74.7842\n",
      "Epoch 87/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 53.1834\n",
      "Epoch 00087: val_loss improved from 74.78423 to 74.37919, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 157us/step - loss: 65.6997 - val_loss: 74.3792\n",
      "Epoch 88/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 57.0371\n",
      "Epoch 00088: val_loss improved from 74.37919 to 73.95006, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 188us/step - loss: 65.0743 - val_loss: 73.9501\n",
      "Epoch 89/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 60.1892\n",
      "Epoch 00089: val_loss improved from 73.95006 to 73.50053, saving model to ./best_weight_boston.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 0s 178us/step - loss: 64.5601 - val_loss: 73.5005\n",
      "Epoch 90/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 61.4104\n",
      "Epoch 00090: val_loss improved from 73.50053 to 72.99984, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 152us/step - loss: 64.0103 - val_loss: 72.9998\n",
      "Epoch 91/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 61.8191\n",
      "Epoch 00091: val_loss improved from 72.99984 to 72.66866, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 167us/step - loss: 63.5331 - val_loss: 72.6687\n",
      "Epoch 92/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 47.8043\n",
      "Epoch 00092: val_loss improved from 72.66866 to 72.26913, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 156us/step - loss: 63.0550 - val_loss: 72.2691\n",
      "Epoch 93/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 56.5960\n",
      "Epoch 00093: val_loss improved from 72.26913 to 71.90356, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 158us/step - loss: 62.5918 - val_loss: 71.9036\n",
      "Epoch 94/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 55.6757\n",
      "Epoch 00094: val_loss improved from 71.90356 to 71.53704, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 150us/step - loss: 62.2199 - val_loss: 71.5370\n",
      "Epoch 95/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 57.0884\n",
      "Epoch 00095: val_loss improved from 71.53704 to 71.23779, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 137us/step - loss: 61.8055 - val_loss: 71.2378\n",
      "Epoch 96/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 59.5596\n",
      "Epoch 00096: val_loss improved from 71.23779 to 71.05775, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 151us/step - loss: 61.4048 - val_loss: 71.0577\n",
      "Epoch 97/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 76.1394\n",
      "Epoch 00097: val_loss improved from 71.05775 to 70.90553, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 192us/step - loss: 61.0301 - val_loss: 70.9055\n",
      "Epoch 98/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 38.6778\n",
      "Epoch 00098: val_loss improved from 70.90553 to 70.75729, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 243us/step - loss: 60.7294 - val_loss: 70.7573\n",
      "Epoch 99/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 77.9007\n",
      "Epoch 00099: val_loss improved from 70.75729 to 70.45116, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 181us/step - loss: 60.3693 - val_loss: 70.4512\n",
      "Epoch 100/100\n",
      "128/323 [==========>...................] - ETA: 0s - loss: 58.8941\n",
      "Epoch 00100: val_loss improved from 70.45116 to 70.21668, saving model to ./best_weight_boston.hdf5\n",
      "323/323 [==============================] - 0s 179us/step - loss: 60.0698 - val_loss: 70.2167\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(filepath=\"./best_weight_boston.hdf5\",verbose=1,\n",
    "                              save_best_only=True)\n",
    "hist = model1.fit(x_train,y_train,batch_size=128,epochs=100,validation_split=0.2,\n",
    "                 callbacks=[checkpointer],verbose=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 99us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "score_1 = model1.evaluate(x_test,y_test)\n",
    "100*score_1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.09"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "92.09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MSE(y, Y):\n",
    "    return np.sum(np.sum(-Y*np.log(y.T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nn import NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "Progress: 0.3% ... Training loss: -6426 ... Validation loss: -1069"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/Udacity_dp_nanodegree/neural_network/deep-learning/first-neural-network/nn.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0ma3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mz4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_3_4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0ma4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0mz5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_4_5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Udacity_dp_nanodegree/neural_network/deep-learning/first-neural-network/nn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# Note: in Python, you can define a function with a lambda expression,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# as shown below.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Replace 0 with your sigmoid calculation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%pdb\n",
    "import sys\n",
    "\n",
    "####################\n",
    "### Set the hyperparameters in you myanswers.py file ###\n",
    "####################\n",
    "\n",
    "from nn import iterations, learning_rate, hidden_nodes, output_nodes\n",
    "\n",
    "delta = []\n",
    "N_i = X_train_matrix.shape[1]\n",
    "network = NeuralNetwork(N_i, hidden_nodes, output_nodes, learning_rate)\n",
    "\n",
    "losses = {'train':[], 'validation':[]}\n",
    "for ii in range(iterations):\n",
    "    # Go through a random batch of 128 records from the training data set\n",
    "    batch = np.random.choice(y_train_df.index, size=128)\n",
    "    X, y = X_train_matrix[batch], y_train[batch]\n",
    "    \n",
    "    network.train(X, y)\n",
    "    \n",
    "    \n",
    "    # Printing out the training progress\n",
    "    train_loss = MSE(network.run(X_train_matrix).T, y_train)\n",
    "    val_loss = MSE(network.run(X_test_flatten).T, y_test_one_hot)\n",
    "    sys.stdout.write(\"\\rProgress: {:2.1f}\".format(100 * ii/float(iterations)) \\\n",
    "                     + \"% ... Training loss: \" + str(train_loss)[:5] \\\n",
    "                     + \" ... Validation loss: \" + str(val_loss)[:5])\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    losses['train'].append(train_loss)\n",
    "    losses['validation'].append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(y.shape)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.78113223e-20,   2.06115362e-09,   9.99999998e-01],\n",
       "       [  4.29549702e-61,   1.23394576e-04,   9.99876605e-01],\n",
       "       [  1.12533283e-07,   1.67014200e-05,   9.99983186e-01],\n",
       "       [  8.80797078e-01,   1.19202922e-01,   2.24045327e-13]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=np.array([[1,25,45],[-78,52,61],[75,80,91],[34,32,5]])\n",
    "c=np.exp(b)/np.sum(np.exp(b),axis=1,keepdims=True)\n",
    "np.argma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(c,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.49342711720049e+19"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " 2.71828183e+00+  7.20048993e+10+   3.49342711e+19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.exp(b),axis=1,keepdims=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
